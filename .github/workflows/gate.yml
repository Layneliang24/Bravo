name: Test Gate - Anti-Cheating Full Test Suite

on:
  pull_request:
    branches: [main, dev]
  push:
    branches: [main, dev]
  workflow_dispatch:
  workflow_call:

jobs:
  full-test-suite:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    strategy:
      matrix:
        node-version: [20.x]
        python-version: [3.11]

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: bravo_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"
          cache-dependency-path: backend/requirements/test.txt

      - name: Install Frontend Dependencies
        working-directory: ./frontend
        run: |
          echo "üì¶ Installing frontend dependencies..."
          npm install --no-audit --no-fund --ignore-scripts
          echo "‚úÖ Frontend dependencies installed"

      - name: Install E2E Dependencies
        working-directory: ./e2e
        run: |
          npm install --no-audit --no-fund --ignore-scripts
          npx playwright install --with-deps
          echo "‚úÖ E2E dependencies installed"

      - name: Install Backend Dependencies
        working-directory: ./backend
        run: |
          pip install -r requirements/test.txt
          echo "‚úÖ Backend dependencies installed"

      # === FRONTEND TESTS ===
      - name: Run Frontend Unit Tests with Coverage
        working-directory: ./frontend
        run: |
          echo "üß™ Running Frontend Unit Tests (FORCED FULL SUITE)"
          npm run test -- --reporter=verbose --coverage --passWithNoTests
          echo "‚úÖ Frontend unit tests completed"
        env:
          CI: true
          JEST_JUNIT_OUTPUT_DIR: ./test-results
          JEST_JUNIT_OUTPUT_NAME: frontend-unit-results.xml

      - name: Run Frontend Component Tests
        working-directory: ./frontend
        run: |
          echo "üß™ Running Frontend Component Tests (FORCED FULL SUITE)"
          npm run test:component -- --reporter=verbose --passWithNoTests
          echo "‚úÖ Frontend component tests completed"

      # === BACKEND TESTS ===
      - name: Run Backend Unit Tests with Coverage
        working-directory: ./backend
        run: |
          echo "üß™ Running Backend Unit Tests (FORCED FULL SUITE)"
          python -m pytest tests/ -m "not integration" --cov=apps --cov=bravo --cov-report=xml --cov-report=html --cov-report=term --junit-xml=test-results/backend-unit-results.xml -v
          echo "‚úÖ Backend unit tests completed"
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/bravo_test
          DJANGO_SETTINGS_MODULE: bravo.settings.test

      - name: Run Backend Integration Tests
        working-directory: ./backend
        run: |
          echo "üß™ Running Backend Integration Tests (FORCED FULL SUITE)"
          python -m pytest tests/ -m integration --junit-xml=test-results/backend-integration-results.xml -v
          echo "‚úÖ Backend integration tests completed"
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/bravo_test
          DJANGO_SETTINGS_MODULE: bravo.settings.test

      # === E2E TESTS ===
      - name: Build Frontend for E2E
        working-directory: ./frontend
        run: |
          npm run build:skip-check || npm run build
          echo "‚úÖ Frontend built for E2E testing"

      - name: Start Backend Server for E2E
        working-directory: ./backend
        run: |
          python manage.py migrate --settings=bravo.settings.test
          python manage.py runserver 8000 --settings=bravo.settings.test &
          sleep 10
          echo "‚úÖ Backend server started for E2E"
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/bravo_test

      - name: Start Frontend Server for E2E
        working-directory: ./frontend
        run: |
          npm run preview -- --port 3000 &
          sleep 5
          echo "‚úÖ Frontend server started for E2E"

      - name: Run E2E Tests with Trace
        working-directory: ./e2e
        run: |
          echo "üß™ Running E2E Tests (FORCED FULL SUITE WITH TRACE)"
          npx playwright test --reporter=html --reporter=junit
          echo "‚úÖ E2E tests completed"
        env:
          PLAYWRIGHT_JUNIT_OUTPUT_NAME: e2e-results.xml

      # === COVERAGE ANALYSIS ===
      - name: Generate Coverage Reports
        run: |
          echo "üìä Generating comprehensive coverage reports"
          # Frontend coverage
          cd frontend && npx nyc report --reporter=text-lcov > ../coverage-frontend.lcov
          # Backend coverage already generated
          cd ../backend && cp coverage.xml ../coverage-backend.xml
          echo "‚úÖ Coverage reports generated"

      - name: Check Coverage Thresholds
        run: |
          echo "üîç Checking coverage thresholds (ANTI-CHEATING)"
          # This will fail the build if thresholds are not met
          cd frontend && npm run test:coverage-check
          cd ../backend && python -m pytest --cov=apps --cov=bravo --cov-fail-under=90 --cov-report=term-missing
          echo "‚úÖ All coverage thresholds met"

      # === PERFORMANCE TESTS ===
      - name: Run Lighthouse Performance Tests
        run: |
          echo "‚ö° Running Lighthouse Performance Tests"
          npm install -g @lhci/cli
          lhci autorun --upload.target=temporary-public-storage
          echo "‚úÖ Performance tests completed"

      # === UPLOAD ARTIFACTS ===
      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ github.run_number }}
          path: |
            frontend/test-results/
            backend/test-results/
            e2e/test-results/
            e2e/playwright-report/
            frontend/coverage/
            backend/htmlcov/
          retention-days: 30

      - name: Upload Coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage-frontend.lcov,./coverage-backend.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: true

      # === ANTI-CHEATING VERIFICATION ===
      - name: Verify Test Execution Integrity
        run: |
          echo "üîí ANTI-CHEATING: Verifying test execution integrity"

          # Check that all expected test result files exist
          test -f frontend/test-results/frontend-unit-results.xml || (echo "‚ùå Frontend unit test results missing" && exit 1)
          test -f frontend/test-results/frontend-component-results.xml || (echo "‚ùå Frontend component test results missing" && exit 1)
          test -f backend/test-results/backend-unit-results.xml || (echo "‚ùå Backend unit test results missing" && exit 1)
          test -f backend/test-results/backend-integration-results.xml || (echo "‚ùå Backend integration test results missing" && exit 1)
          test -f e2e/e2e-results.xml || (echo "‚ùå E2E test results missing" && exit 1)

          # Check that coverage files exist and have content
          test -s coverage-frontend.lcov || (echo "‚ùå Frontend coverage file empty or missing" && exit 1)
          test -s coverage-backend.xml || (echo "‚ùå Backend coverage file empty or missing" && exit 1)

          # Verify minimum test counts (prevent fake test runs)
          frontend_tests=$(grep -c "<testcase" frontend/test-results/frontend-unit-results.xml || echo "0")
          backend_tests=$(grep -c "<testcase" backend/test-results/backend-unit-results.xml || echo "0")
          e2e_tests=$(grep -c "<testcase" e2e/e2e-results.xml || echo "0")

          echo "üìä Test execution summary:"
          echo "   Frontend tests: $frontend_tests"
          echo "   Backend tests: $backend_tests"
          echo "   E2E tests: $e2e_tests"

          # Minimum test thresholds (adjust based on your project)
          [ "$frontend_tests" -ge "10" ] || (echo "‚ùå Insufficient frontend tests executed ($frontend_tests < 10)" && exit 1)
          [ "$backend_tests" -ge "20" ] || (echo "‚ùå Insufficient backend tests executed ($backend_tests < 20)" && exit 1)
          [ "$e2e_tests" -ge "5" ] || (echo "‚ùå Insufficient E2E tests executed ($e2e_tests < 5)" && exit 1)

          echo "‚úÖ Test execution integrity verified - NO CHEATING DETECTED"

      # === SUMMARY REPORT ===
      - name: Generate Test Summary
        if: always()
        run: |
          echo "üìã COMPREHENSIVE TEST SUMMARY" >> $GITHUB_STEP_SUMMARY
          echo "================================" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üß™ Test Execution Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Suite | Status | Coverage |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Unit | ‚úÖ | $(grep -o 'lines="[0-9.]*"' frontend/coverage/lcov-report/index.html | head -1 | cut -d'"' -f2 || echo 'N/A')% |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Component | ‚úÖ | Included above |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Unit | ‚úÖ | $(grep -o 'pc_cov">[0-9]*%' backend/htmlcov/index.html | head -1 | cut -d'>' -f2 || echo 'N/A') |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Integration | ‚úÖ | Included above |" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ‚úÖ | Full flow coverage |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üîí Anti-Cheating Verification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ All test suites executed completely" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Coverage thresholds enforced (‚â•90%)" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Test result artifacts uploaded" >> $GITHUB_STEP_SUMMARY
          echo "- ‚úÖ Performance benchmarks completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## üìä Detailed Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- [Playwright HTML Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Coverage Report on Codecov](https://codecov.io/gh/${{ github.repository }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Test Artifacts Download](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
