"""
Task-0è‡ªæ£€æ£€æŸ¥å™¨
éªŒè¯PRDå®Œæ•´æ€§å’Œé¡¹ç›®å‡†å¤‡å°±ç»ªï¼ˆæŒ‰ç…§V4-PART2æ–‡æ¡£è®¾è®¡ï¼‰

Task-0èŒè´£ï¼ˆé’ˆå¯¹æ¯ä¸ªREQ-IDï¼‰ï¼š
1. Subtask-1: éªŒè¯PRDå…ƒæ•°æ®å®Œæ•´æ€§
2. Subtask-2: æ£€æŸ¥æµ‹è¯•ç›®å½•å­˜åœ¨
3. Subtask-3: éªŒè¯APIå¥‘çº¦æ–‡ä»¶
"""

import re
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, List

import yaml


class Task0Checker:
    """Task-0è‡ªæ£€æ£€æŸ¥å™¨ - PRDå®Œæ•´æ€§éªŒè¯"""

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–Task-0æ£€æŸ¥å™¨

        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.strict_mode = config.get("strict_mode", True)
        self.errors = []
        self.warnings = []

    def check(self, files: List[str]) -> List[Dict[str, Any]]:
        """
        æ£€æŸ¥Task-0ï¼ˆPRDå®Œæ•´æ€§éªŒè¯ï¼‰

        Args:
            files: å¾…æ£€æŸ¥çš„æ–‡ä»¶åˆ—è¡¨

        Returns:
            æ£€æŸ¥ç»“æœåˆ—è¡¨
        """
        results = []

        # â­ æ–°å¢ï¼šæ£€æŸ¥tasks.jsonæ–‡ä»¶ï¼ŒéªŒè¯å¯¹åº”çš„PRDçŠ¶æ€
        tasks_json_files = [f for f in files if ".taskmaster/tasks/tasks.json" in f]
        if tasks_json_files:
            tasks_json_result = self._check_tasks_json_prd_status(files)
            if tasks_json_result:
                results.append(tasks_json_result)

        # åªæ£€æŸ¥ä»£ç æ–‡ä»¶ï¼ˆæ’é™¤PRDã€æµ‹è¯•ã€é…ç½®æ–‡ä»¶ï¼‰
        code_files = self._filter_code_files(files)
        print(f"[Task0Checker DEBUG] è¿‡æ»¤åçš„ä»£ç æ–‡ä»¶: {code_files}", file=sys.stderr)
        if not code_files and not tasks_json_files:
            print("[Task0Checker DEBUG] æ²¡æœ‰ä»£ç æ–‡ä»¶æˆ–tasks.jsonï¼Œè·³è¿‡æ£€æŸ¥", file=sys.stderr)
            return results

        # æå–æ‰€æœ‰ç›¸å…³çš„REQ-IDï¼ˆåªä»ä»£ç æ–‡ä»¶ä¸­æå–ï¼‰
        req_ids, format_errors = self._extract_req_ids(code_files)
        print(f"[Task0Checker DEBUG] æå–åˆ°çš„REQ-ID: {req_ids}", file=sys.stderr)
        print(f"[Task0Checker DEBUG] æ ¼å¼é”™è¯¯æ•°é‡: {len(format_errors)}", file=sys.stderr)

        # å¦‚æœæœ‰æ ¼å¼é”™è¯¯ï¼Œå…ˆè¿”å›æ ¼å¼é”™è¯¯
        if format_errors:
            print("[Task0Checker DEBUG] å‘ç°æ ¼å¼é”™è¯¯ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯", file=sys.stderr)
            results.extend(format_errors)
            # æ ¼å¼é”™è¯¯æ˜¯ä¸¥é‡é—®é¢˜ï¼Œç›´æ¥è¿”å›
            return results

        # Subtask-2: æ£€æŸ¥æµ‹è¯•ç›®å½•ï¼ˆå…¨å±€æ£€æŸ¥ï¼Œä¸ä¾èµ–REQ-IDï¼‰
        test_dir_result = self._check_test_directories()
        if test_dir_result:
            results.append(test_dir_result)

        # å¦‚æœæ²¡æœ‰æå–åˆ°REQ-IDï¼Œç»™å‡ºè­¦å‘Š
        if not req_ids:
            results.append(
                {
                    "level": "warning",
                    "message": "Task-0æ£€æŸ¥: æ— æ³•ä»ä»£ç æ–‡ä»¶ä¸­æå–REQ-ID",
                    "file": ", ".join(code_files[:3]),  # æ˜¾ç¤ºå‰3ä¸ªæ–‡ä»¶
                    "help": (
                        "è¯·åœ¨ä»£ç æ–‡ä»¶å¤´éƒ¨æ³¨é‡Šä¸­åŒ…å«REQ-IDï¼Œæ ¼å¼ï¼š\n"
                        "  # REQ-ID: REQ-2025-001-user-login\n"
                        "æˆ–\n"
                        "  // REQ-ID: REQ-2025-001-user-login\n\n"
                        "REQ-IDæ ‡å‡†æ ¼å¼ï¼šREQ-YYYY-NNN-description\n"
                        "ç¤ºä¾‹ï¼šREQ-2025-001-user-login\n\n"
                        "å¦‚æœæ²¡æœ‰REQ-IDï¼ŒTask-0æ— æ³•éªŒè¯PRDå®Œæ•´æ€§ã€‚"
                    ),
                }
            )
            return results  # æ²¡æœ‰REQ-IDæ—¶ï¼Œåªè¿”å›æµ‹è¯•ç›®å½•æ£€æŸ¥å’Œè­¦å‘Š

        # å¯¹æ¯ä¸ªREQ-IDæ‰§è¡ŒTask-0æ£€æŸ¥
        for req_id in req_ids:
            # Subtask-1: éªŒè¯PRDå…ƒæ•°æ®
            prd_result = self._validate_prd_metadata(req_id)
            if prd_result:
                results.append(prd_result)

            # Subtask-3: éªŒè¯APIå¥‘çº¦
            api_result = self._validate_api_contract(req_id)
            if api_result:
                results.append(api_result)

            # Subtask-4: æ£€æŸ¥Task Masterä»»åŠ¡æ’åº
            ordering_result = self._check_task_ordering(req_id)
            if ordering_result:
                results.append(ordering_result)

            # Subtask-5: æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å±•å¼€
            expansion_result = self._check_task_expansion(req_id)
            if expansion_result:
                results.append(expansion_result)

            # Subtask-6: æ£€æŸ¥txtæ–‡ä»¶ç”Ÿæˆ
            files_result = self._check_task_files_generated(req_id)
            if files_result:
                results.append(files_result)

        return results

    def _filter_code_files(self, files: List[str]) -> List[str]:
        """
        è¿‡æ»¤å‡ºä»£ç æ–‡ä»¶

        Args:
            files: æ–‡ä»¶åˆ—è¡¨

        Returns:
            ä»£ç æ–‡ä»¶åˆ—è¡¨
        """
        code_files = []
        exclude_patterns = [
            "docs/",
            "tests/",
            ".compliance/",
            ".github/",
            "scripts/",
            ".taskmaster/",
            "node_modules/",
            "venv/",
            "__pycache__/",
        ]

        for file in files:
            # æ’é™¤éä»£ç æ–‡ä»¶
            if any(pattern in file for pattern in exclude_patterns):
                continue

            # åªæ£€æŸ¥Pythonå’ŒTypeScript/JavaScriptæ–‡ä»¶
            if file.endswith((".py", ".ts", ".tsx", ".js", ".jsx", ".vue")):
                code_files.append(file)

        return code_files

    def _extract_req_ids(
        self, files: List[str]
    ) -> tuple[List[str], List[Dict[str, Any]]]:
        """
        ä»æ–‡ä»¶åˆ—è¡¨ä¸­æå–REQ-ID

        Args:
            files: æ–‡ä»¶åˆ—è¡¨

        Returns:
            (REQ-IDåˆ—è¡¨ï¼ˆå»é‡ï¼‰, æ ¼å¼é”™è¯¯åˆ—è¡¨)
        """
        req_ids = set()
        format_errors = []  # å­˜å‚¨ä¸ç¬¦åˆæ ¼å¼çš„REQ-IDé”™è¯¯ä¿¡æ¯

        # REQ-IDæ ‡å‡†æ ¼å¼ï¼šREQ-YYYY-NNN-description
        # ç¤ºä¾‹ï¼šREQ-2025-001-user-login
        # æ ¼å¼è¦æ±‚ï¼š
        # - REQ- å‰ç¼€ï¼ˆå¿…é¡»ï¼‰
        # - 4ä½å¹´ä»½ï¼ˆYYYYï¼Œå¿…é¡»ï¼‰
        # - 3ä½åºå·ï¼ˆNNNï¼Œå¿…é¡»ï¼‰
        # - æè¿°ï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼Œå¿…é¡»ï¼‰
        req_id_pattern = re.compile(r"REQ-\d{4}-\d{3}-[a-z0-9-]+", re.IGNORECASE)

        for file in files:
            print(f"[Task0Checker DEBUG] å¤„ç†æ–‡ä»¶: {file}", file=sys.stderr)
            # 1. ä»æ–‡ä»¶è·¯å¾„ä¸­æå–REQ-ID
            match = req_id_pattern.search(file)
            if match:
                req_id = match.group(0).upper()  # ç»Ÿä¸€è½¬ä¸ºå¤§å†™
                print(f"[Task0Checker DEBUG] ä»è·¯å¾„æå–åˆ°REQ-ID: {req_id}", file=sys.stderr)
                req_ids.add(req_id)
                continue

            # 2. å°è¯•ä»æ–‡ä»¶å†…å®¹ä¸­æå–
            try:
                # å¤„ç†ç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„
                path = Path(file)
                if not path.is_absolute():
                    # ç›¸å¯¹è·¯å¾„ï¼šå°è¯•å¤šä¸ªå¯èƒ½çš„æ ¹ç›®å½•
                    possible_paths = [
                        path,  # å½“å‰ç›®å½•
                        Path("/app") / path,  # Dockerå®¹å™¨å†…è·¯å¾„
                        Path(".") / path,  # é¡¹ç›®æ ¹ç›®å½•
                    ]
                else:
                    possible_paths = [path]

                # å…ˆå°è¯•ä»æ–‡ä»¶ç³»ç»Ÿè¯»å–
                content = None
                for possible_path in possible_paths:
                    if possible_path.exists() and possible_path.suffix in [
                        ".py",
                        ".ts",
                        ".tsx",
                        ".js",
                        ".jsx",
                        ".vue",
                    ]:
                        content = possible_path.read_text(
                            encoding="utf-8", errors="ignore"
                        )
                        break

                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»gitæš‚å­˜åŒºè¯»å–ï¼ˆpre-commité˜¶æ®µï¼‰
                if content is None:
                    print(
                        f"[Task0Checker DEBUG] æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»gitæš‚å­˜åŒºè¯»å–: {file}",
                        file=sys.stderr,
                    )
                    try:
                        result = subprocess.run(
                            ["git", "show", f":{file}"],
                            capture_output=True,
                            text=True,
                            check=False,
                            cwd="/app",
                        )
                        if result.returncode == 0:
                            content = result.stdout
                            msg = (
                                f"[Task0Checker DEBUG] ä»gitæš‚å­˜åŒºè¯»å–æˆåŠŸï¼Œ"
                                f"å†…å®¹é•¿åº¦: {len(content)}"
                            )
                            print(msg, file=sys.stderr)
                        else:
                            print(
                                f"[Task0Checker DEBUG] git showå¤±è´¥: {result.stderr}",
                                file=sys.stderr,
                            )
                    except Exception as e:
                        print(f"[Task0Checker DEBUG] git showå¼‚å¸¸: {e}", file=sys.stderr)

                # å¦‚æœè¯»å–åˆ°å†…å®¹ï¼Œè¿›è¡ŒREQ-IDæå–å’Œæ ¼å¼æ£€æŸ¥
                if content:
                    line_count = len(content.split(chr(10)))
                    msg = f"[Task0Checker DEBUG] å¼€å§‹è§£ææ–‡ä»¶å†…å®¹ï¼Œè¡Œæ•°: {line_count}"
                    print(msg, file=sys.stderr)
                    # æ£€æŸ¥å‰30è¡Œï¼ˆå¢åŠ èŒƒå›´ï¼‰
                    lines = content.split("\n")[:30]
                    for line_num, line in enumerate(lines, 1):
                        # å…ˆå°è¯•åŒ¹é…æ ‡å‡†æ ¼å¼
                        match = req_id_pattern.search(line)
                        if match:
                            req_id = match.group(0).upper()
                            msg = (
                                f"[Task0Checker DEBUG] ç¬¬{line_num}è¡ŒåŒ¹é…åˆ°"
                                f"æ ‡å‡†æ ¼å¼REQ-ID: {req_id}"
                            )
                            print(msg, file=sys.stderr)
                            req_ids.add(req_id)
                            break

                        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸ç¬¦åˆæ ¼å¼çš„REQ-ID
                        # åŒ¹é…ä»»ä½•ä»¥REQ-å¼€å¤´çš„å®Œæ•´æ ‡è¯†ç¬¦ï¼ˆè‡³å°‘åŒ…å«ä¸€ä¸ªè¿å­—ç¬¦ï¼‰
                        # é¿å…åŒ¹é…åˆ° "REQ-ID:" è¿™æ ·çš„æ³¨é‡Šæ ‡ç­¾
                        invalid_match = re.search(
                            r"REQ-[A-Z0-9]+(?:-[A-Z0-9-]+)+", line, re.IGNORECASE
                        )
                        if invalid_match:
                            invalid_req_id = invalid_match.group(0)
                            msg = (
                                f"[Task0Checker DEBUG] ç¬¬{line_num}è¡Œå‘ç°"
                                f"å¯èƒ½çš„REQ-ID: {invalid_req_id}"
                            )
                            print(msg, file=sys.stderr)
                            # éªŒè¯æ˜¯å¦ç¬¦åˆæ ‡å‡†æ ¼å¼
                            if not req_id_pattern.match(invalid_req_id):
                                msg = (
                                    f"[Task0Checker DEBUG] REQ-IDæ ¼å¼ä¸æ­£ç¡®: "
                                    f"{invalid_req_id}"
                                )
                                print(msg, file=sys.stderr)
                                # ç¡®å®šæ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨å®é™…è·¯å¾„ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹è·¯å¾„ï¼‰
                                file_path_for_error = file
                                for pp in possible_paths:
                                    if pp.exists():
                                        file_path_for_error = str(pp)
                                        break

                                format_errors.append(
                                    {
                                        "level": "error",
                                        "message": (
                                            f"Task-0æ£€æŸ¥å¤±è´¥: REQ-IDæ ¼å¼ä¸æ­£ç¡®\n"
                                            f"å‘ç°: {invalid_req_id}"
                                        ),
                                        "file": file_path_for_error,
                                        "help": (
                                            "REQ-IDå¿…é¡»ç¬¦åˆæ ‡å‡†æ ¼å¼ï¼š"
                                            "REQ-YYYY-NNN-description\n"
                                            "ç¤ºä¾‹ï¼šREQ-2025-001-user-login\n\n"
                                            f"å½“å‰æ ¼å¼ï¼š{invalid_req_id}\n"
                                            f"æ ¼å¼è¦æ±‚ï¼š\n"
                                            f"  - REQ- å‰ç¼€ï¼ˆå¿…é¡»ï¼‰\n"
                                            f"  - 4ä½å¹´ä»½ï¼ˆYYYYï¼Œå¿…é¡»ï¼‰\n"
                                            f"  - 3ä½åºå·ï¼ˆNNNï¼Œå¿…é¡»ï¼‰\n"
                                            f"  - æè¿°ï¼ˆå°å†™å­—æ¯ã€æ•°å­—ã€è¿å­—ç¬¦ï¼Œå¿…é¡»ï¼‰\n\n"
                                            f"è¯·ä¿®æ­£ç¬¬ {line_num} è¡Œçš„REQ-IDæ ¼å¼ã€‚"
                                        ),
                                    }
                                )
                    break  # æ‰¾åˆ°æ–‡ä»¶åä¸å†å°è¯•å…¶ä»–è·¯å¾„
            except Exception:
                # æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè·³è¿‡
                pass

        return list(req_ids), format_errors

    def _validate_prd_metadata(self, req_id: str) -> Dict[str, Any]:
        """
        Subtask-1: éªŒè¯PRDå…ƒæ•°æ®å®Œæ•´æ€§

        Args:
            req_id: éœ€æ±‚ID

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›é”™è¯¯
        """
        # æ„å»ºPRDæ–‡ä»¶è·¯å¾„ï¼ˆå°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼‰
        possible_prd_paths = [
            Path(f"docs/00_product/requirements/{req_id}/{req_id}.md"),  # ç›¸å¯¹è·¯å¾„
            Path(
                f"/app/docs/00_product/requirements/{req_id}/{req_id}.md"
            ),  # Dockerå®¹å™¨å†…è·¯å¾„
        ]

        prd_path = None
        for possible_path in possible_prd_paths:
            if possible_path.exists():
                prd_path = possible_path
                break

        # æ£€æŸ¥PRDæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if prd_path is None:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè·¯å¾„ä½œä¸ºé”™è¯¯ä¿¡æ¯ä¸­çš„è·¯å¾„
            prd_path = possible_prd_paths[0]
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: PRDæ–‡ä»¶ä¸å­˜åœ¨",
                "file": str(prd_path),
                "help": (
                    f"éœ€æ±‚ {req_id} ç¼ºå°‘PRDæ–‡ä»¶ã€‚\n"
                    f"è¯·å…ˆåˆ›å»ºPRDæ–‡ä»¶: {prd_path}\n"
                    "PRDå¿…é¡»åŒ…å«å®Œæ•´çš„YAML frontmatterå…ƒæ•°æ®ã€‚"
                ),
            }

        # è¯»å–å¹¶è§£æPRD
        try:
            content = prd_path.read_text(encoding="utf-8")

            # æå–Frontmatter
            if not content.startswith("---"):
                return {
                    "level": "error",
                    "message": "Task-0æ£€æŸ¥å¤±è´¥: PRDç¼ºå°‘YAML frontmatter",
                    "file": str(prd_path),
                    "help": "PRDæ–‡ä»¶å¿…é¡»ä»¥YAML frontmatterå¼€å§‹ï¼ˆ---ï¼‰",
                }

            parts = content.split("---", 2)
            if len(parts) < 3:
                return {
                    "level": "error",
                    "message": "Task-0æ£€æŸ¥å¤±è´¥: PRD frontmatteræ ¼å¼é”™è¯¯",
                    "file": str(prd_path),
                    "help": "Frontmatterå¿…é¡»ä»¥---å¼€å§‹å’Œç»“æŸ",
                }

            # è§£æYAML
            metadata = yaml.safe_load(parts[1])

            # â­ æ–°å¢ï¼šPRDçŠ¶æ€æœºæ£€æŸ¥
            status_check_result = self._check_prd_status_for_development(
                prd_path, metadata
            )
            if status_check_result:
                return status_check_result

            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ["test_files", "implementation_files"]
            missing_fields = []

            for field in required_fields:
                if field not in metadata:
                    missing_fields.append(field)
                elif not metadata[field]:
                    missing_fields.append(f"{field} (ä¸ºç©º)")

            if missing_fields:
                return {
                    "level": "error",
                    "message": (
                        "Task-0æ£€æŸ¥å¤±è´¥: PRDå…ƒæ•°æ®ä¸å®Œæ•´\n" f"ç¼ºå°‘å­—æ®µ: {', '.join(missing_fields)}"
                    ),
                    "file": str(prd_path),
                    "help": (
                        "PRDçš„YAML frontmatterå¿…é¡»åŒ…å«ï¼š\n"
                        "- test_files: æµ‹è¯•æ–‡ä»¶åˆ—è¡¨\n"
                        "- implementation_files: å®ç°æ–‡ä»¶åˆ—è¡¨\n"
                        "- api_contract: APIå¥‘çº¦æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰\n\n"
                        "ç¤ºä¾‹ï¼š\n"
                        "---\n"
                        "req_id: REQ-2025-001\n"
                        "test_files:\n"
                        "  - backend/tests/unit/test_example.py\n"
                        "implementation_files:\n"
                        "  - backend/apps/example/views.py\n"
                        "---"
                    ),
                }

            # æ£€æŸ¥api_contractå­—æ®µï¼ˆå¯é€‰ä½†å»ºè®®æœ‰ï¼‰
            if "api_contract" not in metadata or not metadata["api_contract"]:
                self.warnings.append(
                    {
                        "level": "warning",
                        "message": "Task-0å»ºè®®: PRDç¼ºå°‘api_contractå­—æ®µ",
                        "file": str(prd_path),
                        "help": "å»ºè®®åœ¨PRDä¸­å®šä¹‰APIå¥‘çº¦æ–‡ä»¶è·¯å¾„ï¼Œä¾¿äºAPIå¼€å‘",
                    }
                )

            return None  # æ£€æŸ¥é€šè¿‡

        except yaml.YAMLError as e:
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: PRD YAMLè§£æé”™è¯¯",
                "file": str(prd_path),
                "help": f"YAMLè§£æé”™è¯¯: {str(e)}",
            }
        except Exception as e:
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: è¯»å–PRDæ—¶å‡ºé”™",
                "file": str(prd_path),
                "help": f"é”™è¯¯è¯¦æƒ…: {str(e)}",
            }

    def _check_test_directories(self) -> Dict[str, Any]:
        """
        Subtask-2: æ£€æŸ¥æµ‹è¯•ç›®å½•æ˜¯å¦å­˜åœ¨

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™è¿”å›é”™è¯¯
        """
        required_dirs = [
            "backend/tests/unit/",
            "backend/tests/integration/",
            "e2e/tests/",
        ]

        missing_dirs = []
        for dir_path in required_dirs:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼ˆå¤„ç†Dockerå®¹å™¨å†…è·¯å¾„ï¼‰
            possible_paths = [
                Path(dir_path),  # ç›¸å¯¹è·¯å¾„
                Path("/app") / dir_path,  # Dockerå®¹å™¨å†…è·¯å¾„
            ]

            found = False
            for possible_path in possible_paths:
                if possible_path.exists():
                    found = True
                    break

            if not found:
                missing_dirs.append(dir_path)

        if missing_dirs:
            return {
                "level": "error",
                "message": (f"Task-0æ£€æŸ¥å¤±è´¥: æµ‹è¯•ç›®å½•ä¸å­˜åœ¨\nç¼ºå°‘ç›®å½•: {', '.join(missing_dirs)}"),
                "file": "æµ‹è¯•ç›®å½•ç»“æ„",
                "help": (
                    "è¯·åˆ›å»ºå¿…éœ€çš„æµ‹è¯•ç›®å½•ï¼š\n"
                    "  mkdir -p backend/tests/unit\n"
                    "  mkdir -p backend/tests/integration\n"
                    "  mkdir -p backend/tests/regression\n"
                    "  mkdir -p e2e/tests/smoke\n"
                    "  mkdir -p e2e/tests/regression\n\n"
                    "è¿™äº›ç›®å½•æ˜¯TDDå¼€å‘çš„åŸºç¡€è®¾æ–½ã€‚"
                ),
            }

        return None  # æ£€æŸ¥é€šè¿‡

    def _validate_api_contract(self, req_id: str) -> Dict[str, Any]:
        """
        Subtask-3: éªŒè¯APIå¥‘çº¦æ–‡ä»¶

        Args:
            req_id: éœ€æ±‚ID

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœAPIå¥‘çº¦æœ‰é—®é¢˜åˆ™è¿”å›é”™è¯¯
        """
        # æ„å»ºAPIå¥‘çº¦æ–‡ä»¶è·¯å¾„ï¼ˆå°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼‰
        possible_contract_paths = [
            Path(f"docs/01_guideline/api-contracts/{req_id}/{req_id}-api.yaml"),  # ç›¸å¯¹è·¯å¾„
            Path(
                f"/app/docs/01_guideline/api-contracts/{req_id}/{req_id}-api.yaml"
            ),  # Dockerå®¹å™¨å†…è·¯å¾„
        ]

        contract_path = None
        for possible_path in possible_contract_paths:
            if possible_path.exists():
                contract_path = possible_path
                break

        # æ£€æŸ¥APIå¥‘çº¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if contract_path is None:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªè·¯å¾„ä½œä¸ºé”™è¯¯ä¿¡æ¯ä¸­çš„è·¯å¾„
            contract_path = possible_contract_paths[0]
            # APIå¥‘çº¦æ˜¯å¯é€‰çš„ï¼Œä½†å»ºè®®æœ‰
            return {
                "level": "warning",
                "message": "Task-0å»ºè®®: APIå¥‘çº¦æ–‡ä»¶ä¸å­˜åœ¨",
                "file": str(contract_path),
                "help": (
                    f"å»ºè®®ä¸º {req_id} åˆ›å»ºAPIå¥‘çº¦æ–‡ä»¶ã€‚\n"
                    "APIå¥‘çº¦æ–‡ä»¶ç”¨äºå®šä¹‰æ¥å£è§„èŒƒï¼Œä¾¿äºå‰åç«¯åä½œã€‚\n\n"
                    "åˆ›å»ºæ­¥éª¤ï¼š\n"
                    f"  mkdir -p docs/01_guideline/api-contracts/{req_id}\n"
                    f"  # åˆ›å»ºOpenAPI 3.0è§„èŒƒæ–‡ä»¶\n"
                    f"  # {contract_path}"
                ),
            }

        # éªŒè¯APIå¥‘çº¦æ ¼å¼
        try:
            content = contract_path.read_text(encoding="utf-8")
            api_spec = yaml.safe_load(content)

            # æ£€æŸ¥OpenAPIç‰ˆæœ¬
            if "openapi" not in api_spec:
                return {
                    "level": "error",
                    "message": "Task-0æ£€æŸ¥å¤±è´¥: APIå¥‘çº¦ç¼ºå°‘openapiç‰ˆæœ¬å­—æ®µ",
                    "file": str(contract_path),
                    "help": "APIå¥‘çº¦æ–‡ä»¶å¿…é¡»åŒ…å«openapiç‰ˆæœ¬å­—æ®µï¼ˆå¦‚: openapi: 3.0.0ï¼‰",
                }

            # æ£€æŸ¥pathså®šä¹‰
            if "paths" not in api_spec or not api_spec["paths"]:
                return {
                    "level": "error",
                    "message": "Task-0æ£€æŸ¥å¤±è´¥: APIå¥‘çº¦ç¼ºå°‘pathså®šä¹‰",
                    "file": str(contract_path),
                    "help": "APIå¥‘çº¦æ–‡ä»¶å¿…é¡»å®šä¹‰è‡³å°‘ä¸€ä¸ªAPIè·¯å¾„",
                }

            return None  # æ£€æŸ¥é€šè¿‡

        except yaml.YAMLError as e:
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: APIå¥‘çº¦YAMLè§£æé”™è¯¯",
                "file": str(contract_path),
                "help": f"YAMLè§£æé”™è¯¯: {str(e)}",
            }
        except Exception as e:
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: è¯»å–APIå¥‘çº¦æ—¶å‡ºé”™",
                "file": str(contract_path),
                "help": f"é”™è¯¯è¯¦æƒ…: {str(e)}",
            }

    def _check_task_ordering(self, req_id: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥Task Masterä»»åŠ¡æ’åºæ˜¯å¦ç¬¦åˆTDDæµç¨‹

        TDDæ ‡å‡†æµç¨‹ï¼š
        1. ç¼–å†™æµ‹è¯•ï¼ˆçº¢è‰²ï¼‰
        2. å®ç°åŠŸèƒ½
        3. è¿è¡Œæµ‹è¯•ï¼ˆç»¿è‰²ï¼‰
        4. é‡æ„ä¼˜åŒ–

        Args:
            req_id: éœ€æ±‚ID

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›è­¦å‘Š
        """
        # è¯»å–tasks.json
        tasks_file = Path(".taskmaster/tasks/tasks.json")
        if not tasks_file.exists():
            return None

        try:
            import json

            tasks_data = json.loads(tasks_file.read_text(encoding="utf-8"))
        except Exception as e:
            print(f"[Task0Checker] è¯»å–tasks.jsonå¤±è´¥: {e}", file=sys.stderr)
            return None

        # æŸ¥æ‰¾ä¸REQ-IDç›¸å…³çš„ä»»åŠ¡
        related_tasks = self._find_tasks_by_req_id(tasks_data, req_id)

        if not related_tasks:
            return None

        # æ£€æŸ¥ä»»åŠ¡æ’åº
        ordering_issues = []

        for task in related_tasks:
            subtasks = task.get("subtasks", [])
            if not subtasks:
                continue

            # åˆ†æå­ä»»åŠ¡é¡ºåº
            test_keywords = ["æµ‹è¯•", "test", "å•å…ƒæµ‹è¯•", "é›†æˆæµ‹è¯•", "ç¼–å†™æµ‹è¯•"]

            first_task_is_test = False
            if subtasks:
                first_title = subtasks[0].get("title", "").lower()
                first_desc = subtasks[0].get("description", "").lower()
                first_task_is_test = any(
                    kw in first_title or kw in first_desc for kw in test_keywords
                )

            if not first_task_is_test:
                ordering_issues.append(
                    f"ä»»åŠ¡ {task['id']} '{task['title']}' å»ºè®®ç¬¬ä¸€ä¸ªå­ä»»åŠ¡åº”è¯¥æ˜¯" "'ç¼–å†™æµ‹è¯•'ï¼ˆTDDçº¢è‰²é˜¶æ®µï¼‰"
                )

        if ordering_issues:
            # ä»é…ç½®ä¸­è¯»å–å¸®åŠ©ä¿¡æ¯
            task_master_config = self.config.get("task_master_checks", {})
            ordering_config = task_master_config.get("task_ordering", {})
            help_text = ordering_config.get(
                "help",
                (
                    "å‘ç°ä»¥ä¸‹æ’åºå»ºè®®ï¼š\n"
                    + "\n".join(f"  - {issue}" for issue in ordering_issues)
                    + "\n\nTDDæœ€ä½³å®è·µæµç¨‹ï¼š\n"
                    "1. å­ä»»åŠ¡1ï¼šç¼–å†™å¤±è´¥çš„æµ‹è¯•ï¼ˆçº¢è‰²é˜¶æ®µï¼‰\n"
                    "2. å­ä»»åŠ¡2-Nï¼šå®ç°åŠŸèƒ½ç›´åˆ°æµ‹è¯•é€šè¿‡ï¼ˆç»¿è‰²é˜¶æ®µï¼‰\n"
                    "3. å­ä»»åŠ¡N+1ï¼šé‡æ„ä¼˜åŒ–ï¼ˆä¿æŒæµ‹è¯•é€šè¿‡ï¼‰\n\n"
                    "è¿™æ ·å¯ä»¥ç¡®ä¿ï¼š\n"
                    "- æµ‹è¯•é©±åŠ¨å¼€å‘\n"
                    "- é˜²æ­¢è¿‡åº¦è®¾è®¡\n"
                    "- æŒç»­éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§"
                ),
            )

            return {
                "level": ordering_config.get("level", "warning"),
                "message": "Task Masterä»»åŠ¡æ’åºå»ºè®®ä¼˜åŒ–ï¼ˆTDDæµç¨‹ï¼‰",
                "file": ".taskmaster/tasks/tasks.json",
                "help": help_text.replace(
                    "{issues}", "\n".join(f"  - {issue}" for issue in ordering_issues)
                ),
            }

        return None

    def _check_task_expansion(self, req_id: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å±•å¼€ä¸ºå­ä»»åŠ¡

        é¿å…è¿‡ç²—ç²’åº¦çš„ä»»åŠ¡ç›´æ¥å®æ–½

        Args:
            req_id: éœ€æ±‚ID

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›è­¦å‘Š
        """
        tasks_file = Path(".taskmaster/tasks/tasks.json")
        if not tasks_file.exists():
            return None

        try:
            import json

            tasks_data = json.loads(tasks_file.read_text(encoding="utf-8"))
        except Exception:
            return None

        related_tasks = self._find_tasks_by_req_id(tasks_data, req_id)

        if not related_tasks:
            return None

        unexpanded_tasks = []

        # ä»é…ç½®ä¸­è¯»å–æœ€å°å¤æ‚åº¦é˜ˆå€¼
        task_master_config = self.config.get("task_master_checks", {})
        expansion_config = task_master_config.get("task_expansion", {})
        min_complexity = expansion_config.get("min_complexity_for_expansion", 5)

        for task in related_tasks:
            subtasks = task.get("subtasks", [])

            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å±•å¼€
            if not subtasks or len(subtasks) == 0:
                # åˆ¤æ–­ä»»åŠ¡å¤æ‚åº¦ï¼ˆç®€å•ä»»åŠ¡å¯ä»¥ä¸å±•å¼€ï¼‰
                complexity = task.get("complexity", 5)
                if complexity >= min_complexity:  # ä½¿ç”¨é…ç½®çš„é˜ˆå€¼
                    unexpanded_tasks.append(
                        {
                            "id": task["id"],
                            "title": task["title"],
                            "complexity": complexity,
                        }
                    )

        if unexpanded_tasks:
            task_list = "\n".join(
                [
                    f"  - ä»»åŠ¡ {t['id']}: {t['title']} (å¤æ‚åº¦: {t['complexity']}/10)"
                    for t in unexpanded_tasks
                ]
            )

            # ä½¿ç”¨é…ç½®çš„å¸®åŠ©ä¿¡æ¯
            help_text = expansion_config.get(
                "help",
                (
                    f"ä»¥ä¸‹ä»»åŠ¡å¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®å±•å¼€ä¸ºå­ä»»åŠ¡ï¼š\n{task_list}\n\n"
                    "å±•å¼€æ–¹æ³•ï¼š\n"
                    "1. åˆ†æä»»åŠ¡å¤æ‚åº¦ï¼štask-master analyze-complexity --research\n"
                    "2. å±•å¼€å•ä¸ªä»»åŠ¡ï¼štask-master expand --id=<ä»»åŠ¡ID> --research\n"
                    "3. æ‰¹é‡å±•å¼€æ‰€æœ‰ä»»åŠ¡ï¼štask-master expand --all --research\n\n"
                    "å±•å¼€åçš„å­ä»»åŠ¡å¯ä»¥ï¼š\n"
                    "- æä¾›æ›´æ¸…æ™°çš„å®æ–½è·¯å¾„\n"
                    "- ä¾¿äºè·Ÿè¸ªè¿›åº¦\n"
                    "- é™ä½å•ä¸ªä»»åŠ¡çš„å¤æ‚åº¦"
                ),
            )

            return {
                "level": expansion_config.get("level", "warning"),
                "message": "éƒ¨åˆ†ä»»åŠ¡æœªå±•å¼€ä¸ºå­ä»»åŠ¡",
                "file": ".taskmaster/tasks/tasks.json",
                "help": help_text.replace("{task_list}", task_list),
            }

        return None

    def _check_task_files_generated(self, req_id: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥Task Masteræ˜¯å¦ç”Ÿæˆäº†txtæ–‡ä»¶

        txtæ–‡ä»¶ç”¨äºAIæŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…

        Args:
            req_id: éœ€æ±‚ID

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›æç¤º
        """
        tasks_file = Path(".taskmaster/tasks/tasks.json")
        if not tasks_file.exists():
            return None

        try:
            import json

            tasks_data = json.loads(tasks_file.read_text(encoding="utf-8"))
        except Exception:
            return None

        related_tasks = self._find_tasks_by_req_id(tasks_data, req_id)

        if not related_tasks:
            return None

        # æ£€æŸ¥tasksç›®å½•ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„txtæ–‡ä»¶
        tasks_dir = Path(".taskmaster/tasks")
        missing_files = []

        for task in related_tasks:
            task_id = task["id"]
            # Task Masterç”Ÿæˆçš„æ–‡ä»¶æ ¼å¼å¯èƒ½æ˜¯task-{id}.txtæˆ–task-{id}.md
            task_file_txt = tasks_dir / f"task-{task_id}.txt"
            task_file_md = tasks_dir / f"task-{task_id}.md"

            if not task_file_txt.exists() and not task_file_md.exists():
                missing_files.append({"id": task_id, "title": task["title"]})

        if missing_files:
            file_list = "\n".join(
                [f"  - task-{f['id']}.txt ({f['title']})" for f in missing_files]
            )

            # ä»é…ç½®ä¸­è¯»å–å¸®åŠ©ä¿¡æ¯
            task_master_config = self.config.get("task_master_checks", {})
            files_config = task_master_config.get("task_files_generation", {})
            help_text = files_config.get(
                "help",
                (
                    f"ç¼ºå°‘ä»¥ä¸‹ä»»åŠ¡æ–‡ä»¶ï¼š\n{file_list}\n\n"
                    "ç”Ÿæˆæ–¹æ³•ï¼š\n"
                    "  task-master generate\n\n"
                    "txt/mdæ–‡ä»¶çš„ä½œç”¨ï¼š\n"
                    "- æ–¹ä¾¿AIæŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…ï¼ˆæ— éœ€è§£æJSONï¼‰\n"
                    "- æä¾›äººç±»å¯è¯»çš„ä»»åŠ¡æè¿°\n"
                    "- ç”¨äºé¡¹ç›®æ–‡æ¡£å’Œä»»åŠ¡è¿½è¸ª"
                ),
            )

            return {
                "level": files_config.get("level", "info"),
                "message": "éƒ¨åˆ†Task Masterä»»åŠ¡æœªç”Ÿæˆtxt/mdæ–‡ä»¶",
                "file": ".taskmaster/tasks/",
                "help": help_text.replace("{file_list}", file_list),
            }

        return None

    def _find_tasks_by_req_id(self, tasks_data: dict, req_id: str) -> list:
        """
        ä»tasks.jsonä¸­æŸ¥æ‰¾ä¸REQ-IDç›¸å…³çš„ä»»åŠ¡

        Args:
            tasks_data: tasks.jsonçš„æ•°æ®
            req_id: éœ€æ±‚ID

        Returns:
            ç›¸å…³ä»»åŠ¡åˆ—è¡¨
        """
        related_tasks = []

        # éå†æ‰€æœ‰tag
        for tag_name, tag_data in tasks_data.items():
            if not isinstance(tag_data, dict):
                continue

            tasks = tag_data.get("tasks", [])

            for task in tasks:
                # æ£€æŸ¥ä»»åŠ¡æ ‡é¢˜ã€æè¿°ã€detailsä¸­æ˜¯å¦åŒ…å«REQ-ID
                task_text = " ".join(
                    [
                        str(task.get("title", "")),
                        str(task.get("description", "")),
                        str(task.get("details", "")),
                    ]
                ).upper()

                if req_id.upper() in task_text:
                    related_tasks.append(task)

        return related_tasks

    def _check_prd_status_for_development(
        self, prd_path: Path, metadata: Dict
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥PRDçŠ¶æ€æ˜¯å¦å…è®¸å¼€å‘ï¼ˆçŠ¶æ€æœºæ ¡éªŒï¼‰

        è§„åˆ™ï¼š
        - draft: ä¸å…è®¸æäº¤ä»»ä½•ä»£ç 
        - review: åªå…è®¸ä¿®æ”¹PRDæœ¬èº«ï¼Œä¸å…è®¸æäº¤å®ç°ä»£ç 
        - approved/implementing/completed: å…è®¸å¼€å‘
        - archived: ä¸å…è®¸å¼€å‘

        Args:
            prd_path: PRDæ–‡ä»¶è·¯å¾„
            metadata: PRDå…ƒæ•°æ®

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
        """
        status = metadata.get("status", "").lower()

        # çŠ¶æ€1ï¼šdraft - å®Œå…¨æ‹’ç»
        if status == "draft":
            return {
                "level": "error",
                "message": "Task-0æ£€æŸ¥å¤±è´¥: PRDçŠ¶æ€ä¸ºdraftï¼Œä¸å…è®¸å¼€å‘",
                "file": str(prd_path),
                "help": (
                    "âŒ PRDçŠ¶æ€ä¸º 'draft'ï¼ˆè‰ç¨¿ï¼‰ï¼Œä¸å…è®¸æäº¤å®ç°ä»£ç \n\n"
                    "ğŸ“‹ å¼€å‘å‰ç½®æ¡ä»¶ï¼š\n"
                    "  1. å®Œå–„PRDå†…å®¹\n"
                    "  2. æäº¤å®¡æ ¸ï¼šstatusæ”¹ä¸º 'review'\n"
                    "  3. å®¡æ ¸é€šè¿‡ï¼šstatusæ”¹ä¸º 'approved'\n"
                    "  4. è§£æä»»åŠ¡ï¼štask-master parse-prd\n"
                    "  5. å¼€å§‹å¼€å‘ï¼šstatusè‡ªåŠ¨å˜ä¸º 'implementing'\n\n"
                    "ğŸ”„ å¦‚æœPRDè¿˜åœ¨è‰ç¨¿é˜¶æ®µï¼Œè¯·å…ˆå®Œå–„å†…å®¹å¹¶æäº¤å®¡æ ¸\n\n"
                    "âš ï¸  çŠ¶æ€è½¬æ¢åªèƒ½äººå·¥ä¿®æ”¹ï¼ˆé™¤äº†approvedâ†’implementingæ˜¯è‡ªåŠ¨çš„ï¼‰"
                ),
            }

        # çŠ¶æ€2ï¼šreview - æ£€æŸ¥æ˜¯å¦åœ¨æäº¤å®ç°ä»£ç 
        elif status == "review":
            impl_files = metadata.get("implementation_files", [])

            # è·å–å½“å‰æäº¤çš„æ–‡ä»¶
            staged_files = self._get_staged_files()

            # æ£€æŸ¥æ˜¯å¦æœ‰å®ç°ä»£ç è¢«æäº¤
            blocked_files = []
            for staged_file in staged_files:
                # è·³è¿‡PRDæ–‡ä»¶æœ¬èº«
                if "docs/00_product/requirements" in staged_file:
                    continue

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…implementation_files
                for impl_pattern in impl_files:
                    # ç®€å•åŒ¹é…ï¼šæ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«impl_pattern
                    if impl_pattern in staged_file or staged_file in impl_pattern:
                        blocked_files.append(staged_file)
                        break

            if blocked_files:
                blocked_list = "\n".join(f"  - {f}" for f in blocked_files[:5])
                if len(blocked_files) > 5:
                    blocked_list += f"\n  - ... è¿˜æœ‰ {len(blocked_files) - 5} ä¸ªæ–‡ä»¶"

                return {
                    "level": "error",
                    "message": "Task-0æ£€æŸ¥å¤±è´¥: PRDçŠ¶æ€ä¸ºreviewï¼Œä¸å…è®¸æäº¤å®ç°ä»£ç ",
                    "file": str(prd_path),
                    "help": (
                        "âŒ PRDçŠ¶æ€ä¸º 'review'ï¼ˆå®¡æ ¸ä¸­ï¼‰ï¼Œä¸å…è®¸æäº¤å®ç°ä»£ç \n\n"
                        f"ğŸ“‹ è¢«é˜»æ­¢çš„æ–‡ä»¶ï¼š\n{blocked_list}\n\n"
                        "âœ… å½“å‰å¯ä»¥åšçš„ï¼š\n"
                        "  - ä¿®æ”¹PRDæ–‡ä»¶æœ¬èº«ï¼ˆå®Œå–„éœ€æ±‚ï¼‰\n"
                        "  - æäº¤æ–‡æ¡£ä¿®æ”¹\n\n"
                        "âŒ ä¸å…è®¸åšçš„ï¼š\n"
                        "  - æäº¤implementation_filesä¸­çš„ä»£ç \n\n"
                        "ğŸ”„ ç­‰å¾…PRDå®¡æ ¸é€šè¿‡åå†å¼€å‘ï¼š\n"
                        "  1. å®¡æ ¸äººå°†statusæ”¹ä¸º 'approved'\n"
                        "  2. è¿è¡Œ task-master parse-prd\n"
                        "  3. å¼€å§‹å¼€å‘ï¼ˆstatusè‡ªåŠ¨å˜ä¸º 'implementing'ï¼‰"
                    ),
                }

        # çŠ¶æ€3ï¼šarchived - ä¸å…è®¸å¼€å‘
        elif status == "archived":
            return {
                "level": "warning",
                "message": "Task-0è­¦å‘Š: PRDçŠ¶æ€ä¸ºarchivedï¼Œä¸å»ºè®®ç»§ç»­å¼€å‘",
                "file": str(prd_path),
                "help": (
                    "âš ï¸ PRDçŠ¶æ€ä¸º 'archived'ï¼ˆå·²å½’æ¡£ï¼‰ï¼Œä¸å»ºè®®ç»§ç»­å¼€å‘\n\n"
                    "å¦‚æœéœ€è¦é‡æ–°å¼€å‘ï¼Œè¯·å…ˆè¯„ä¼°éœ€æ±‚æ˜¯å¦ä»ç„¶æœ‰æ•ˆï¼Œ"
                    "å¹¶å°†statusæ”¹å›åˆé€‚çš„çŠ¶æ€ï¼ˆå¦‚draftæˆ–reviewï¼‰"
                ),
            }

        # çŠ¶æ€4ï¼šapproved/implementing/completed - å…è®¸å¼€å‘
        elif status in ["approved", "implementing", "completed"]:
            # é€šè¿‡æ£€æŸ¥
            return None

        # å…¶ä»–æœªçŸ¥çŠ¶æ€
        else:
            return {
                "level": "warning",
                "message": f"Task-0è­¦å‘Š: PRDçŠ¶æ€ '{status}' ä¸åœ¨æ ‡å‡†çŠ¶æ€åˆ—è¡¨ä¸­",
                "file": str(prd_path),
                "help": (
                    f"âš ï¸ PRDçŠ¶æ€ä¸º '{status}'ï¼Œä¸æ˜¯æ ‡å‡†çŠ¶æ€\n\n"
                    "æ ‡å‡†çŠ¶æ€åˆ—è¡¨ï¼š\n"
                    "  - draft: è‰ç¨¿\n"
                    "  - review: å®¡æ ¸ä¸­\n"
                    "  - approved: å·²æ‰¹å‡†ï¼ˆå¯parseï¼‰\n"
                    "  - implementing: å®æ–½ä¸­ï¼ˆparseåè‡ªåŠ¨è®¾ç½®ï¼‰\n"
                    "  - completed: å·²å®Œæˆ\n"
                    "  - archived: å·²å½’æ¡£"
                ),
            }

    def _check_tasks_json_prd_status(self, files: List[str] = None) -> Dict[str, Any]:
        """
        æ£€æŸ¥tasks.jsonå¯¹åº”çš„PRDçŠ¶æ€ï¼ˆpre-commité˜¶æ®µï¼‰

        ä»tasks.jsonçš„metadataä¸­è¯»å–source_prd_pathæˆ–source_prd_pathsï¼Œ
        åªæ£€æŸ¥è¿™äº›PRDçš„çŠ¶æ€ï¼Œé¿å…è¯¯æŠ¥ã€‚

        ç­–ç•¥ï¼š
        1. æ£€æŸ¥tasks.jsonæ˜¯å¦åœ¨filesåˆ—è¡¨ä¸­ï¼ˆè¢«ä¿®æ”¹ï¼‰
        2. å¦‚æœæ˜¯ï¼Œä»tasks.jsonçš„metadataè¯»å–PRDè·¯å¾„
        3. åªæ£€æŸ¥è¿™äº›ç›¸å…³PRDçš„çŠ¶æ€
        4. å¦‚æœå‘ç°ä»»ä½•ç›¸å…³PRDçŠ¶æ€ä¸ºdraft/reviewï¼ŒæŠ¥é”™

        Args:
            files: å¾…æ£€æŸ¥çš„æ–‡ä»¶åˆ—è¡¨ï¼ˆä»check()æ–¹æ³•ä¼ å…¥ï¼‰

        Returns:
            æ£€æŸ¥ç»“æœï¼Œå¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›é”™è¯¯ä¿¡æ¯
        """
        import json

        # æ£€æŸ¥tasks.jsonæ˜¯å¦åœ¨filesåˆ—è¡¨ä¸­ï¼ˆè¢«ä¿®æ”¹ï¼‰
        if files:
            tasks_json_staged = any(".taskmaster/tasks/tasks.json" in f for f in files)
        else:
            # å¦‚æœæ²¡æœ‰ä¼ å…¥filesï¼Œå°è¯•ä»gitæš‚å­˜åŒºè·å–ï¼ˆå…¼å®¹æ€§ï¼‰
            staged_files = self._get_staged_files()
            tasks_json_staged = any(
                ".taskmaster/tasks/tasks.json" in f for f in staged_files
            )

        # å¦‚æœtasks.jsonæ²¡æœ‰è¢«ä¿®æ”¹ï¼Œè·³è¿‡æ£€æŸ¥
        if not tasks_json_staged:
            return None

        # è¯»å–tasks.json
        tasks_json_path = Path(".taskmaster/tasks/tasks.json")
        if not tasks_json_path.exists():
            return None

        try:
            with open(tasks_json_path, "r", encoding="utf-8") as f:
                tasks_data = json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            print(
                f"[Task0Checker] è¯»å–tasks.jsonå¤±è´¥: {e}",
                file=sys.stderr,
            )
            return None

        # æ”¶é›†æ‰€æœ‰éœ€è¦æ£€æŸ¥çš„PRDè·¯å¾„
        prd_paths_to_check = set()

        for tag_name, tag_data in tasks_data.items():
            if not isinstance(tag_data, dict):
                continue

            metadata = tag_data.get("metadata", {})
            if not isinstance(metadata, dict):
                continue

            # æ£€æŸ¥source_prd_pathï¼ˆå•ä¸ªï¼‰
            if "source_prd_path" in metadata:
                prd_paths_to_check.add(metadata["source_prd_path"])

            # æ£€æŸ¥source_prd_pathsï¼ˆæ•°ç»„ï¼‰
            if "source_prd_paths" in metadata:
                prd_paths = metadata["source_prd_paths"]
                if isinstance(prd_paths, list):
                    prd_paths_to_check.update(prd_paths)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•PRDè·¯å¾„ï¼Œè·³è¿‡æ£€æŸ¥
        if not prd_paths_to_check:
            return None

        # æ£€æŸ¥è¿™äº›PRDçš„çŠ¶æ€
        errors = []
        for prd_path in prd_paths_to_check:
            prd_file = Path(prd_path)

            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                prd_file,
                Path("docs/00_product/requirements") / prd_file.name,
                Path("/app/docs/00_product/requirements") / prd_file.name,
            ]

            prd_file_found = None
            for path in possible_paths:
                if path.exists():
                    prd_file_found = path
                    break

            if not prd_file_found:
                errors.append(f"PRDæ–‡ä»¶ä¸å­˜åœ¨: {prd_path}")
                continue

            # è¯»å–PRDçš„frontmatter
            try:
                with open(prd_file_found, "r", encoding="utf-8") as f:
                    content = f.read()

                # è§£æfrontmatter
                parts = content.split("---", 2)
                if len(parts) < 3:
                    errors.append(f"PRD {prd_path} ç¼ºå°‘frontmatter")
                    continue

                metadata_str = parts[1].strip()
                if not metadata_str:
                    errors.append(f"PRD {prd_path} frontmatterä¸ºç©º")
                    continue

                metadata = yaml.safe_load(metadata_str)
                if not isinstance(metadata, dict):
                    errors.append(f"PRD {prd_path} frontmatteræ ¼å¼é”™è¯¯")
                    continue

                # æ£€æŸ¥statuså­—æ®µ
                status = metadata.get("status", "").lower()
                if status in ["draft", "review"]:
                    req_id = metadata.get("req_id", prd_file_found.stem)
                    title = metadata.get("title", "æœªå‘½åPRD")
                    error_msg = (
                        f"PRD '{req_id}' ({title}) çŠ¶æ€ä¸º '{status}'ï¼Œ"
                        f"ä¸å…è®¸ä¿®æ”¹tasks.json\n"
                        f"  æ–‡ä»¶: {prd_path}"
                    )
                    errors.append(error_msg)

            except Exception as e:
                errors.append(f"è¯»å–PRDå¤±è´¥ {prd_path}: {e}")
                continue

        if errors:
            return {
                "level": "error",
                "message": (
                    "tasks.jsonè¢«ä¿®æ”¹ï¼Œä½†ä»¥ä¸‹PRDçŠ¶æ€ä¸æ˜¯'approved'ï¼š\n"
                    + "\n".join(f"  â€¢ {e}" for e in errors)
                    + "\n\nğŸ’¡ è¯·å…ˆå°†PRDçŠ¶æ€æ”¹ä¸º'approved'åå†ä¿®æ”¹tasks.json"
                ),
                "file": ".taskmaster/tasks/tasks.json",
                "help": (
                    "âŒ æ£€æµ‹åˆ°tasks.jsonè¢«ä¿®æ”¹ï¼Œä½†ç›¸å…³PRDçŠ¶æ€ä¸æ˜¯'approved'\n\n"
                    "ğŸ“‹ è§£å†³æ–¹æ¡ˆï¼š\n"
                    "  1. å¦‚æœPRDåº”è¯¥è¢«parseï¼Œè¯·å°†statusæ”¹ä¸º 'approved'\n"
                    "  2. å¦‚æœPRDä¸åº”è¯¥è¢«parseï¼Œè¯·æ’¤é”€tasks.jsonçš„ä¿®æ”¹\n\n"
                    "ğŸ”„ æ ‡å‡†æµç¨‹ï¼š\n"
                    "  1. PRDçŠ¶æ€æ”¹ä¸º 'approved'\n"
                    "  2. è¿è¡Œ task-master parse-prd <prd_file>\n"
                    "  3. PRDçŠ¶æ€è‡ªåŠ¨å˜ä¸º 'implementing'\n"
                    "  4. å¼€å§‹å¼€å‘\n\n"
                    "âš ï¸  æ— è®ºé€šè¿‡å‘½ä»¤è¡Œè¿˜æ˜¯MCPå·¥å…·è°ƒç”¨parse-prdï¼Œ"
                    "éƒ½å¿…é¡»ç¡®ä¿PRDçŠ¶æ€ä¸ºapproved"
                ),
            }

        return None

    def _get_staged_files(self) -> List[str]:
        """
        è·å–gitæš‚å­˜åŒºçš„æ–‡ä»¶åˆ—è¡¨

        Returns:
            æš‚å­˜åŒºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            result = subprocess.run(
                ["git", "diff", "--cached", "--name-only"],
                capture_output=True,
                text=True,
                check=False,
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip().split("\n")
            return []
        except Exception as e:
            print(f"[Task0Checker] è·å–staged fileså¤±è´¥: {e}", file=sys.stderr)
            return []


def create_checker(config: Dict[str, Any]) -> Task0Checker:
    """
    åˆ›å»ºTask-0æ£€æŸ¥å™¨å®ä¾‹

    Args:
        config: é…ç½®å­—å…¸

    Returns:
        Task0Checkerå®ä¾‹
    """
    return Task0Checker(config)
