---
description: Debug阶段的规则和调试方法论
globs: **/*
priority: 600
# 注意：此规则通过意图路由加载，不需要alwaysApply
---
# Debug阶段规则

## 调试方法论（基于30轮CI修复经验）

### 问题抽象层次识别

**核心原则**: 在正确的抽象层次寻找问题根因

**层次识别矩阵**:
```
错误现象 → 可能的抽象层次 → 验证命令
├── 语法错误 → bash脚本层、配置文件层 → act/yamllint
├── 命令不存在 → 环境依赖层、路径配置层 → which/whereis
├── 连接超时 → 网络层、服务配置层 → curl/netstat
├── 404/500错误 → 应用层、路由配置层 → API测试/日志
├── 数据库错误 → 数据层、权限配置层 → SQL测试/权限检查
└── 容器退出 → 容器层、依赖关系层 → docker logs/inspect
```

**步骤**:
1. **症状识别**: 错误表现在哪个层次？
2. **根因定位**: 实际问题发生在哪个层次？
3. **层次跳跃**: 如果当前层次修复无效，检查其他层次

### 系统性问题搜索

**规则**: 发现一个问题时，系统性搜索所有相同问题

**命令**:
```bash
# 全局搜索相同错误模式
grep -r "错误关键词" .

# 查找所有相关文件
find . -name "*.py" -o -name "*.ts" | xargs grep "错误模式"

# 检查历史修复记录
git log --all --grep="类似问题"
```

**原则**: 避免"打地鼠式修复"（修复一个文件，遗漏其他文件）

### 环境差异检查

**规则**: 对比不同环境的配置差异

**检查清单**:
```bash
# 配置文件差异
diff backend/bravo/settings/development.py backend/bravo/settings/test.py
diff docker-compose.yml docker-compose.test.yml

# 工作流文件差异
diff .github/workflows/on-pr.yml .github/workflows/on-push-dev.yml

# 版本一致性
docker --version && echo "vs remote environment"
node --version && echo "vs package.json engines"
```

### 多维验证策略

**四层验证体系**:

1. **语法验证**:
   - 使用act验证GitHub Actions工作流语法
   - 运行本地格式化器和语法检查器
   - **限制**: 只能发现语法错误

2. **环境验证**:
   - 使用docker-compose模拟完整运行环境
   - 验证服务间连通性和依赖关系
   - **关键**: 模拟目标运行环境

3. **功能验证**:
   - 实际执行核心功能和API端点
   - 验证数据库连接和数据操作
   - **方式**: curl/wget测试API

4. **环境差异验证**:
   - 对比不同环境配置文件
   - 检查工作流文件差异
   - 验证工具版本一致性

**参考**: @.cursorrules (多维验证策略部分)

### 自我质疑机制

**触发条件**: 连续失败3次，或遇到特定"调试地狱"场景

**检查清单**:
```
□ 我在正确的抽象层次修复问题吗？
  - bash层 vs 容器层 vs 应用层 vs 数据层？
□ 我有搜索所有相关的文件吗？
  - grep -r "错误模式" . 执行了吗？
□ 我验证了不同环境的配置差异吗？
  - PR环境 vs post-merge环境对比了吗？
□ 我使用了合适的验证工具链吗？
  - act → docker-compose → 功能测试 → 远程验证？
□ 用户的反馈是否指向了不同方向？
  - 质疑信号是否被忽视了？
□ 我是否在"打地鼠式修复"？
  - 系统性搜索 vs 单点修复？
□ **我是否在质疑测试策略本身？**（新增）
  - 这是代码问题还是测试策略问题？
  - 是否有更好的架构层面的解决方案？
  - 我是否陷入了"维修工"思维而不是"架构师"思维？
```

**原则**: 3次失败后必须质疑基础假设和方法论

### 策略质疑机制（新增）

**核心原则**：当遇到"调试地狱"场景时，必须跳出代码层面，质疑测试策略和架构设计。

**"调试地狱"场景识别**：
- 验证码E2E测试失败
- 涉及随机性/不确定性的测试
- 涉及异步竞态条件的测试
- 涉及前后端状态同步的测试
- 连续失败3次以上的测试

**策略质疑检查清单**：
```
□ 这是代码问题还是测试策略问题？
  - 代码逻辑看起来是对的，但测试就是失败？
  - 是否应该质疑"测试策略"本身？
□ 是否有架构层面的解决方案？
  - 万能验证码（测试环境专用）
  - Mock网络请求
  - 绕过验证码的测试模式
□ 我是否陷入了"维修工"思维？
  - 是否在拼命修代码，而不是质疑设计？
  - 是否应该建议用户改变测试策略？
□ 我是否在"盲猜"？
  - 是否缺乏运行时状态信息？
  - 是否需要更多"尸检报告"（截图、日志、网络请求）？
```

**响应策略**：
1. **立即停止修代码**
2. **主动提出架构层面的建议**：
   - "这个问题的根本原因可能是测试策略问题，而不是代码问题"
   - "建议使用万能验证码或Mock接口，而不是尝试识别真正的验证码"
3. **提供"尸检报告"收集方法**：
   - 截图/录像
   - Console日志
   - Network请求记录
   - 定点暂停调试

### 用户反馈价值最大化

**原则**: 用户质疑往往指向真正问题

**响应策略**:
- 用户质疑时立即深度分析
- 考虑完全不同的问题根因
- 不要忽视用户的质疑信号

## 主动工具使用（强制要求）

**核心原则**: AI必须主动、善于利用各种工具进行调试和排查，不要等用户要求才使用

### MCP工具（浏览器验证）

**强制要求**: 每次修复前端问题后，必须主动使用MCP工具验证浏览器环境

**必须执行的检查**:
1. **打开页面并检查控制台错误**:
   ```typescript
   // 1. 打开页面
   browser_navigate("http://localhost:3000/your-page");

   // 2. 主动检查控制台错误（关键！）
   const consoleMessages = browser_console_messages();
   // 查找: CORS错误、网络错误、JavaScript错误、资源加载失败

   // 3. 检查网络请求
   const networkRequests = browser_network_requests();
   // 验证: API请求是否成功、状态码是否正确
   ```

2. **主动截图验证**:
   ```typescript
   // 如果发现问题，主动截图保存证据
   browser_take_screenshot({ filename: "error-state.png" });
   ```

3. **主动交互测试**:
   ```typescript
   // 主动测试关键功能
   browser_click({ element: "登录按钮", ref: "button.login" });
   browser_type({ element: "用户名输入框", ref: "input.username", text: "test" });
   ```

**禁止行为**:
- ❌ 不能等用户报告浏览器错误才修复
- ❌ 不能只验证容器内测试，必须验证浏览器实际运行效果
- ❌ 不能跳过MCP工具验证

### Playwright工具（E2E测试和调试）

**主动使用场景**:
1. **E2E测试失败时**:
   ```bash
   # 主动运行playwright调试模式
   cd e2e && npx playwright test --debug

   # 主动查看测试报告
   npx playwright show-report

   # 主动查看trace文件
   npx playwright show-trace trace.zip
   ```

2. **前端功能验证**:
   ```bash
   # 主动运行playwright UI模式进行交互式调试
   npx playwright test --ui

   # 主动生成测试代码
   npx playwright codegen http://localhost:3000
   ```

3. **截图和视频分析**:
   ```bash
   # 主动查看失败测试的截图和视频
   ls test-results/
   # 分析截图和视频，找出问题根因
   ```

**主动行为要求**:
- ✅ 测试失败时，主动运行playwright调试模式
- ✅ 主动查看测试报告和trace文件
- ✅ 主动分析截图和视频，找出问题根因

### GitHub CLI工具（gh）

**主动使用场景**:
1. **CI/CD问题排查**:
   ```bash
   # 主动查看GitHub Actions运行状态
   gh run list --limit 10

   # 主动查看失败的workflow详情
   gh run view <run-id> --log-failed

   # 主动查看PR状态和检查
   gh pr view <pr-number> --json state,statusCheckRollup
   ```

2. **PR管理**:
   ```bash
   # 主动检查PR合并状态
   gh pr checks <pr-number>

   # 主动查看PR的详细状态
   gh pr view <pr-number> --json mergeable,mergeStateStatus
   ```

3. **问题追踪**:
   ```bash
   # 主动查看相关issue
   gh issue list --label "bug"

   # 主动查看commit历史
   gh api repos/:owner/:repo/commits --jq '.[] | {sha: .sha, message: .commit.message}'
   ```

**主动行为要求**:
- ✅ CI/CD失败时，主动使用gh查看workflow状态和日志
- ✅ PR相关问题时，主动使用gh查看PR状态和检查
- ✅ 需要GitHub信息时，主动使用gh而不是等用户提供

### 其他工具包

**Docker工具**:
```bash
# 主动检查容器状态
docker-compose ps
docker-compose logs backend
docker-compose exec backend python manage.py shell

# 主动检查容器资源使用
docker stats
```

**Git工具**:
```bash
# 主动查看git状态和历史
git status
git log --oneline -10
git diff HEAD~1

# 主动搜索git历史
git log --all --grep="类似问题"
git log -S "错误模式"
```

**系统工具**:
```bash
# 主动检查进程和端口
ps aux | grep python
netstat -tulpn | grep 8000

# 主动检查文件系统
df -h
du -sh *
```

### 工具使用原则

**主动性原则**:
- ✅ **主动使用工具**：不要等用户要求，发现问题立即使用工具排查
- ✅ **工具优先**：能用工具解决的问题，不要猜测或假设
- ✅ **多工具组合**：一个问题可能要用多个工具从不同角度验证

**禁止行为**:
- ❌ 不能等用户提供信息，应该主动使用工具获取
- ❌ 不能只依赖用户描述，应该主动验证实际情况
- ❌ 不能跳过工具验证，直接猜测问题原因

## Docker容器调试

### 查看容器日志

```bash
# 查看所有服务日志
docker-compose logs

# 查看特定服务日志
docker-compose logs backend
docker-compose logs frontend

# 实时跟踪日志
docker-compose logs -f backend
```

### 进入容器调试

```bash
# 进入backend容器
docker-compose exec backend bash

# 进入frontend容器
docker-compose exec frontend bash

# 在容器内执行命令
docker-compose exec backend python manage.py shell
docker-compose exec backend pytest -v
```

### 检查容器状态

```bash
# 查看容器状态
docker-compose ps

# 查看容器详细信息
docker-compose inspect backend

# 查看容器资源使用
docker stats
```

## 问题记录

**规则**: 解决困难后必须记录

**记录位置**: `DOCS/FAQ.md`

**记录内容**:
- 问题描述
- 错误消息
- 尝试的解决方案
- 最终解决方案
- 抽象层次判断经验
- 方法论教训

**参考**: @.cursorrules (解决困难后部分)

## 禁止事项

- ❌ 不能连续失败3次后继续尝试
- ❌ 不能只修复表面错误，不找根因
- ❌ 不能忽略用户反馈
- ❌ 不能跳过环境差异检查
- ❌ 不能"打地鼠式修复"（修复一个文件，遗漏其他）
- ❌ **不能等用户要求才使用工具**：必须主动使用MCP、playwright、gh等工具
- ❌ **不能跳过工具验证**：发现问题必须主动使用工具验证，不能猜测
- ❌ **不能只依赖用户描述**：必须主动使用工具获取实际情况

---

## 规则应用声明

**当AI被路由到此规则时，必须在响应开头明确声明**：

```
[应用规则：@.cursor/rules/05-debugging/debugging-methodology.mdc]
```

**注意**：本规则不要求切换到特定角色，执行调试流程即可。

**验证要求**：
- ✅ 必须明确声明应用了此规则
- ✅ 必须遵循本规则中的所有约束和流程
- ✅ 不能跳过声明步骤直接执行操作
