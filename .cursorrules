# 🐳 DOCKER开发项目 - 重要提醒 🐳

## ⚠️ 核心开发模式：纯Docker容器化开发 ⚠️

**🚨 关键信息 - 请务必遵守：**

- **开发模式**：纯Docker容器化开发，无需本地安装Python/Node.js/MySQL
- **启动命令**：`docker-compose up` (不是 npm run dev)
- **服务架构**：MySQL + Redis + Django + Vue + Celery (全在容器内)
- **代码编辑**：宿主机编辑，容器内运行
- **依赖管理**：容器内自动处理，宿主机只保留开发工具

**🛑 绝对禁止的操作：**
- ❌ 建议安装本地Python虚拟环境
- ❌ 建议安装本地MySQL/Redis
- ❌ 建议pip install或python manage.py等本地命令
- ❌ 建议npm install在frontend/e2e目录（除非是开发工具需要）

**✅ 正确的开发操作：**
- ✅ 使用docker-compose up启动全部服务
- ✅ 容器内执行Python/Django命令
- ✅ 使用docker-compose logs查看日志
- ✅ 如需进入容器：docker-compose exec [service] bash

**📋 服务端口映射：**
- Frontend (Vue): http://localhost:3000
- Backend (Django): http://localhost:8000
- MySQL: localhost:3306
- Redis: localhost:6379

---

# Bravo项目开发规范

## 核心原则

### 核心信念
- **渐进式改进而非大刀阔斧** - 小幅修改，确保能编译并通过测试
- **从现有代码中学习** - 先研究和规划，再实施
- **实用主义而非教条主义** - 适应项目现实
- **清晰意图而非聪明代码** - 选择平实和明显的方案

### 问题解决哲学（基于30轮CI修复经验）
- **正确抽象层次优先** - 在合适的层次寻找问题根因，避免层次混乱
- **用户反馈价值最大化** - 用户质疑往往指向真正问题，立即深入分析
- **系统性思维而非点修复** - 发现一个问题时，系统性搜索所有相同问题
- **自我质疑机制常态化** - 连续失败3次必须质疑基础假设和方法论
- **多维验证策略** - 单一工具验证不足，需要语法+环境+功能多层验证

### 简洁性意味着
- 每个函数/类只有单一职责
- 避免过早抽象
- 不要使用巧妙技巧 - 选择平实的解决方案
- 如果需要解释，说明太复杂了

## 流程

### 1. 规划与分阶段

将复杂工作分解为3-5个阶段。按照项目层级在 `DOCS/IMPLEMENTATION_PLAN.md` 中记录：
```markdown
## 阶段 N：[名称]
**目标**：[具体交付物]
**成功标准**：[可测试的结果]
**测试**：[具体测试用例]
**状态**：[未开始|进行中|完成]
```
- 根据进度更新状态
- 所有阶段完成后删除文件

### 2. 实施流程

1. **理解** - 研究代码库中的现有模式
2. **测试** - 先写测试（红色）
3. **实现** - 最少代码通过测试（绿色）
4. **多维验证** - 避免30轮修复的验证缺陷
5. **提交** - 推送代码并触发CI

#### 多维验证策略（基于30轮修复教训）

**第一层：语法验证**
- 使用act验证GitHub Actions工作流语法
- 运行本地格式化器和语法检查器
- **限制**：只能发现语法错误，无法发现环境和功能问题

**第二层：环境验证**
- 使用docker-compose模拟完整运行环境
- 验证服务间连通性和依赖关系
- 检查环境变量传递和配置文件差异
- **关键**：模拟目标运行环境（测试/生产）

**第三层：功能验证**
- 实际执行核心功能和API端点
- 验证数据库连接和数据操作
- 检查用户可见的功能是否正常
- **验证方式**：curl/wget测试API，数据库查询验证

**第四层：环境差异验证**
- 对比不同环境配置文件（开发vs测试vs生产）
- 检查工作流文件差异（PR vs post-merge）
- 验证工具版本一致性
- **系统性检查**：`find . -name "*.yml" -o -name "*.py" | grep -E "(test|dev|prod)"`

### 3. 遇到困难时（3次尝试后）

**关键**：每个问题最多尝试3次，然后停止。

#### 立即执行的问题分析流程
1. **记录失败内容**：
   - 你尝试了什么
   - 具体的错误消息
   - 你认为失败的原因

2. **抽象层次检查**（30轮修复核心教训）：
   - **当前在哪个层次**：bash/脚本层、容器层、应用层、数据层？
   - **错误真正发生在哪个层次**：症状层次 vs 根因层次
   - **层次跳跃验证**：如果bash层修复无效，问题可能在应用层

3. **环境差异系统性检查**：
   - **多环境配置文件差异**：开发vs测试vs生产环境配置
   - **工作流文件差异**：PR环境vs post-merge环境
   - **工具版本差异**：本地vs远程Docker/Node/Python版本

4. **质疑基础假设**：
   - 这是正确的抽象层次吗？
   - 能否分解为更小的问题？
   - 是否有完全更简单的方法？
   - **用户反馈是否指向了不同方向？**

5. **系统性问题搜索**：
   - **全局搜索相同问题**：`grep -r "相同错误模式" .`
   - **找到所有相关文件**：避免修复一个文件遗漏其他文件
   - **检查历史修复记录**：类似问题之前如何解决

6. **解决困难后**：
   - 记录解决困难的过程和结果到 `DOCS/FAQ.md` 中
   - **更新问题定位方法论**：记录抽象层次判断经验

## 技术标准

### 架构原则
- **组合优于继承** - 使用依赖注入
- **接口优于单例** - 提高测试能力和灵活性
- **显式优于隐式** - 清晰的数据流和依赖关系
- **尽可能测试驱动** - 永远不要禁用测试，而是修复它们

### 代码质量

- **每次提交必须**：
  - 编译成功
  - 通过所有现有测试
  - 包含新功能的测试
  - 遵循项目格式化/语法检查规范

- **提交前**：
  - 运行格式化器/语法检查器
  - 自我审查修改
  - 确保提交消息解释"为什么"

### 错误处理

- 快速失败并提供描述性消息
- 包含调试上下文
- 在适当层级处理错误
- 永远不要静默吞掉异常

## 决策框架

当存在多个有效方法时，基于以下标准选择：

1. **可测试性** - 我能轻松测试这个吗？
2. **可读性** - 6个月后有人能理解这个吗？
3. **一致性** - 这符合项目模式吗？
4. **简洁性** - 这是最简单的可行解决方案吗？
5. **可逆性** - 以后修改有多困难？

## 项目集成

### 学习代码库

- 找到3个类似的功能/组件
- 识别通用模式和约定
- 尽可能使用相同的库/工具
- 遵循现有测试模式

### 工具

- 使用项目现有的构建系统
- 使用项目的测试框架
- 使用项目的格式化器/语法检查器设置
- 没有强有力的理由不要引入新工具
- 知晓你所掌握的工具，比如act，docker，git，github CLI等等，并合理使用

#### 工具边界认知（30轮修复核心教训）

**act工具局限性**：
- ✅ **适用场景**：GitHub Actions语法验证、基本逻辑检查
- ❌ **不适用场景**：服务容器环境、环境变量复杂传递、跨服务通信
- ⚠️ **误区**：以为act验证通过=远程CI也会成功

**docker-compose工具能力**：
- ✅ **适用场景**：完整环境模拟、服务间连通性、数据持久化
- ✅ **推荐用法**：每次修复前先本地docker-compose验证
- ⚠️ **注意**：版本差异、本地vs远程环境配置

**问题定位工具选择矩阵**：
- **语法问题** → act + 本地linter
- **环境问题** → docker-compose + 容器内调试
- **应用问题** → 直接功能测试 + 日志分析
- **配置问题** → 文件对比 + 系统性搜索

**验证工具链组合**：
1. act（语法） → docker-compose（环境） → 功能测试（应用） → 远程验证
2. 每个层次失败时，不要跳到下一层次，先解决当前层次问题

#### npm workspaces架构设计原则（基于30轮修复洞察）

**核心架构理念**：
- npm workspaces使用**全局视角**管理所有依赖
- 任何破坏这个全局视角的操作都会导致依赖结构损坏
- 必须严格遵循"单一依赖管理入口"原则

**设计模式**：
```bash
# ✅ 正确的依赖管理模式
根目录: npm ci --prefer-offline --no-audit    # 唯一的依赖管理入口
子目录: npm run build/test                    # 只执行构建和测试，不管理依赖

# ❌ 错误的依赖管理模式
子目录: npm ci                               # 会破坏全局依赖树
子目录: npm install                          # 会导致依赖漂移
```

**架构检查清单**：
- [ ] 所有CI工作流只在根目录运行npm ci
- [ ] 子目录只执行npm run命令，不执行npm ci/install
- [ ] 共享依赖放在根目录，通过workspaces机制共享
- [ ] 工具类依赖统一管理，使用npx执行

## 质量关卡

### 完成定义

- [ ] 测试已编写并通过
- [ ] 代码遵循项目约定
- [ ] 无语法检查器/格式化器警告
- [ ] 提交消息清晰
- [ ] 实现符合计划
- [ ] 没有不带问题编号的TODO

### 测试指南

- 测试行为，不是实现
- 尽可能每个测试一个断言
- 清晰的测试名称描述场景
- 使用现有的测试工具/辅助函数
- 测试应该是确定性的

## 重要提醒
- **基础设施搭建**：工作前先检查基础设施，比如docker，mysql，redis，act，github CLI等，基础设施越完善，工作效率越高。
- **docker容器化开发**：不要使用宿主机进行开发测试，所有操作都在容器中进行并且优先使用国内源，包括构建，下载依赖，运行测试等。
- **虚拟环境开发**：避免污染系统环境，应使用虚拟环境
- **永远不要**：
  - 使用 `--no-verify` 绕过提交钩子
  - 禁用测试而不是修复它们
  - 提交无法编译的代码
  - 做假设 - 通过现有代码验证
- **始终**：
  - 逐步提交可工作的代码
  - 随时更新计划文档
  - 从现有实现中学习
  - 3次失败尝试后停止并重新评估
- **命令行交互**：不要进入python 交互环境，不然会卡死。
- **表明身份**：每次对话，请标注是由哪个模型回答的，并给出真实模型名称。

## 教训

> 由AI填写，写一些通用的，行为准则方面的教训
### 规范遵守
- **绝不绕过项目规范**：遇到困难时修复问题，而不是绕过检查流程
- **深入分析根因**：不要只修复表面错误，要找到真正的问题源头
- **系统性解决问题**：建立检查清单，一次性找出所有相关问题

### 技术理解
- **理解工具上下文**：npm workspaces、容器环境等有特定的命令执行规则
- **本地验证优先**：所有修复都必须在本地环境验证通过再推送
- **从失败中学习**：每次错误都要记录原因和解决方案，避免重复犯错

### 代码修复陷阱
- **不要为了修复Lint而破坏功能**：ESLint命名问题应通过配置规则解决，而非修改工作代码
- **Vue组件命名规则严格**：kebab-case是标准，'el-card'不能改为ElCard，会破坏组件识别
- **保护历史成功配置**：已验证工作的配置（如第5轮成功版本）不可轻易修改
- **修复时验证核心功能**：不能只看Lint通过，必须确保功能逻辑不受影响

### CI/CD修复方法论（30轮修复核心总结）

#### npm依赖管理的血泪教训（30轮修复根因）
- **核心问题**：CI环境中滥用npm install导致依赖漂移灾难
- **技术原理**：npm install会更新package-lock.json，破坏版本一致性
- **workspaces机制**：错误的依赖安装顺序破坏npm workspaces结构
- **恶性循环**：依赖漂移 → npm install强制修复 → 更多漂移 → 30轮修复

**🎯 深层架构洞察（终极发现）**：
- **npm workspaces设计原理**：只应在根目录运行依赖管理命令
- **子目录npm ci的破坏性**：会重新评估整个workspace依赖树
- **deduped机制冲突**：导致共享依赖被错误移除或重新定位
- **这是固有行为特性**：不是配置问题，而是npm workspaces的内在机制

**严格规范（基于架构级理解）**：
- ✅ **CI环境**：必须使用`npm ci`，确保版本严格一致
- ✅ **workspace原则**：**绝对只在根目录**运行npm ci
- ✅ **工具管理**：所有工具添加到devDependencies，使用npx执行
- ❌ **绝对禁止**：CI中使用`npm install`（包括`npm install -g`）
- ❌ **严重禁止**：子目录的任何npm ci调用（会破坏整个workspace结构）

#### 根本原因识别失误的防范
- **层次混乱**：30轮在bash层修复，实际问题在Django应用层
- **症状vs根因**：错误日志显示bash语法错误，真正原因是URL配置冲突
- **依赖管理层次**：30轮修复忽视了依赖管理抽象层次的根本问题
- **防范策略**：连续失败3次，必须跳到不同抽象层次重新分析

#### 本地验证策略缺陷的修正
- **工具局限性**：act只能验证语法，无法发现环境和应用问题
- **验证层次缺失**：缺少docker-compose环境验证和功能验证
- **环境差异忽视**：PR环境vs测试环境使用不同配置文件
- **依赖漂移检测**：必须验证npm workspaces依赖安装顺序正确性
- **修正策略**：建立4层验证体系（语法→环境→功能→差异）

#### 打地鼠式修复的避免
- **系统性搜索缺失**：修复一个文件中的问题，遗漏其他文件相同问题
- **全局视角缺乏**：没有搜索所有相关配置文件和工作流文件
- **依赖漂移补丁**：不能用npm install补丁掩盖根本的依赖管理问题
- **避免策略**：发现问题时立即执行`grep -r "问题模式" .`全局搜索

#### 用户反馈价值的最大化
- **质疑信号识别**：用户质疑"为什么死都修复不了"指向方法论错误
- **技术洞察力价值**：用户要求"本地验证"直接发现了真正根因
- **响应策略**：用户质疑时立即深度分析，往往指向被忽视的关键问题

#### 实时记录和自我进化
- **记录延迟问题**：修复过程中没有及时更新调试记录
- **自我学习缺失**：没有从每轮失败中提取方法论教训
- **改进策略**：每轮修复必须实时记录，定期总结方法论

## 持续集成工作流程

### GitHub Actions监控流程
当创建PR或合并到dev分支时，必须严格执行以下监控流程：

1. **实时监控**：每60秒检查一次GitHub Actions状态
2. **立即响应**：任何工作流失败必须立即创建修复方案
3. **循环验证**：修复后重新执行，直到所有工作流全部通过
4. **多角度分析**：持续失败时需从不同角度思考问题根源

### 分支管理规范
- **严格分支保护**：dev和main分支禁止直接推送
- **Feature分支开发**：所有开发必须在feature分支进行
- **PR合并流程**：feature → dev → main，每个环节都必须通过CI验证
- **清理策略**：定期清理已完成合并的feature分支

### 故障排查原则
- **基础设施优先**：检查docker、依赖、环境配置等基础设施
- **多维验证策略**：act（语法）→ docker-compose（环境）→ 功能测试（应用）→ 远程验证
- **日志分析**：详细分析失败日志，定位具体问题
- **渐进式修复**：小步快跑，确保每次修复都能带来进展
- **记录总结**：所有问题和解决方案必须记录到FAQ文档

### 调试方法论（30轮修复血泪教训）

#### 避免"打地鼠式修复"的系统性调试流程

**1. 问题抽象层次识别**：
- **症状识别**：错误表现在哪个层次（bash、容器、应用、数据）
- **根因定位**：实际问题发生在哪个层次
- **层次跳跃检查**：如果当前层次修复无效，检查其他层次

#### 抽象层次识别矩阵（关键操作指导）
```
错误现象 → 可能的抽象层次 → 验证命令
├── 语法错误 → bash脚本层、配置文件层 → act/yamllint
├── 命令不存在 → 环境依赖层、路径配置层 → which/whereis
├── 连接超时 → 网络层、服务配置层 → curl/netstat
├── 404/500错误 → 应用层、路由配置层 → API测试/日志
├── 数据库错误 → 数据层、权限配置层 → SQL测试/权限检查
└── 容器退出 → 容器层、依赖关系层 → docker logs/inspect
```

#### 环境差异检查清单
```bash
# 配置文件差异检查
diff backend/bravo/settings/development.py backend/bravo/settings/test.py
diff docker-compose.yml docker-compose.test.yml

# 工作流文件差异检查
diff .github/workflows/on-pr.yml .github/workflows/on-push-dev.yml

# 版本一致性检查
docker --version && echo "vs remote environment"
node --version && echo "vs package.json engines"
```

**2. 系统性问题搜索**：
- **全局搜索**：`grep -r "错误关键词" .`
- **模式匹配**：查找所有相似的代码模式
- **配置文件对比**：`diff`比较不同环境配置
- **历史修复检查**：查看相同问题的历史解决方案

**3. 环境差异识别**：
- **多环境配置**：开发vs测试vs生产环境配置文件
- **工作流差异**：PR环境vs post-merge环境
- **工具版本差异**：本地vs远程容器、依赖版本

**4. 用户反馈价值识别**：
- **质疑信号**：用户质疑往往指向被忽视的问题角度
- **立即分析**：用户提出质疑时，立即深入分析
- **方向转换**：如果用户质疑修复方向，考虑完全不同的问题根因

**5. 自我质疑触发机制**：
- **3次失败规则**：连续失败3次必须质疑基础假设
- **方法论检查**：问题定位方法是否正确
- **抽象层次检查**：是否在错误层次寻找问题
- **工具适用性检查**：使用的工具是否适合当前问题类型

#### 自我质疑检查清单（连续3次失败后执行）
```
□ 我在正确的抽象层次修复问题吗？
  - bash层 vs 容器层 vs 应用层 vs 数据层？
□ 我有搜索所有相关的文件吗？
  - grep -r "错误模式" . 执行了吗？
□ 我验证了不同环境的配置差异吗？
  - PR环境 vs post-merge环境对比了吗？
□ 我使用了合适的验证工具链吗？
  - act → docker-compose → 功能测试 → 远程验证？
□ 用户的反馈是否指向了不同方向？
  - 质疑信号是否被忽视了？
□ 我是否在"打地鼠式修复"？
  - 系统性搜索 vs 单点修复？
```
