#!/usr/bin/env python3
"""
éªŒè¯åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸å·¥ä½œæµJobåç§°ä¸€è‡´æ€§
ç¡®ä¿åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸­è¦æ±‚çš„æ‰€æœ‰jobåç§°éƒ½åœ¨å·¥ä½œæµä¸­å­˜åœ¨
"""

import io
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Optional, Set

import yaml

# ä¿®å¤Windowsç»ˆç«¯ä¸­æ–‡ä¹±ç é—®é¢˜
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")


def extract_job_names_from_workflow(workflow_file: Path) -> Set[str]:
    """ä»å·¥ä½œæµæ–‡ä»¶ä¸­æå–æ‰€æœ‰jobåç§°"""
    with open(workflow_file, encoding="utf-8") as f:
        workflow = yaml.safe_load(f)

    jobs = workflow.get("jobs", {})
    job_names = set()

    for job_id, job_config in jobs.items():
        # ä¼˜å…ˆä½¿ç”¨jobçš„nameå­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨job_id
        job_display_name = job_config.get("name", job_id)

        # æ·»åŠ job IDï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
        job_names.add(job_id)
        # æ·»åŠ jobçš„æ˜¾ç¤ºåç§°ï¼ˆGitHubå®é™…ä½¿ç”¨çš„åç§°ï¼‰
        job_names.add(job_display_name)

        # å¦‚æœä½¿ç”¨matrixç­–ç•¥ï¼Œç”Ÿæˆæ‰€æœ‰ç»„åˆ
        strategy = job_config.get("strategy", {})
        matrix = strategy.get("matrix", {})
        if matrix:
            # æå–matrixçš„é”®å’Œå€¼
            matrix_keys = list(matrix.keys())
            matrix_values = {}

            for key in matrix_keys:
                values = matrix[key]
                if isinstance(values, list):
                    matrix_values[key] = values
                elif isinstance(values, dict):
                    # å¤„ç†include/excludeç­‰å¤æ‚æƒ…å†µ
                    if "include" in values:
                        # ç®€åŒ–å¤„ç†ï¼šåªæå–includeä¸­çš„å€¼
                        matrix_values[key] = [
                            item.get(key) for item in values["include"] if key in item
                        ]

            # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
            if matrix_values:
                # ç®€åŒ–ï¼šåªç”Ÿæˆç¬¬ä¸€ä¸ªé”®çš„æ‰€æœ‰å€¼ç»„åˆ
                first_key = matrix_keys[0]
                if first_key in matrix_values:
                    for value in matrix_values[first_key]:
                        # ç”Ÿæˆæ ¼å¼: job_name (value) å’Œ job_id (value)
                        combined_name_id = f"{job_id} ({value})"
                        combined_name_display = f"{job_display_name} ({value})"
                        job_names.add(combined_name_id)
                        job_names.add(combined_name_display)

    return job_names


def get_workflow_name(workflow_file: Path) -> str:
    """è·å–å·¥ä½œæµçš„æ˜¾ç¤ºåç§°"""
    with open(workflow_file, encoding="utf-8") as f:
        workflow = yaml.safe_load(f)

    return workflow.get("name", workflow_file.stem)


def parse_all_workflow_jobs() -> Dict[str, Dict]:
    """è§£ææ‰€æœ‰å·¥ä½œæµæ–‡ä»¶ï¼Œæå–jobä¿¡æ¯"""
    workflows_dir = Path(".github/workflows")
    if not workflows_dir.exists():
        return {}

    workflow_files = list(workflows_dir.glob("*.yml")) + list(
        workflows_dir.glob("*.yaml")
    )

    all_jobs = {}

    for workflow_file in workflow_files:
        # è·³è¿‡æŸäº›ç‰¹æ®Šå·¥ä½œæµ
        if workflow_file.name in ["workflow-validation-monitor.yml"]:
            continue

        workflow_name = get_workflow_name(workflow_file)
        job_names = extract_job_names_from_workflow(workflow_file)

        all_jobs[workflow_name] = {
            "file": str(workflow_file),
            "jobs": job_names,
        }

    return all_jobs


def get_github_repo_info() -> Optional[tuple[str, str]]:
    """è·å–GitHubä»“åº“çš„ownerå’Œrepoåç§°"""
    try:
        # å°è¯•ä»git remoteè·å–
        result = subprocess.run(
            ["git", "remote", "get-url", "origin"],
            capture_output=True,
            text=True,
            check=True,
        )
        remote_url = result.stdout.strip()

        # è§£æURLæ ¼å¼: git@github.com:owner/repo.git æˆ– https://github.com/owner/repo.git
        if "github.com" in remote_url:
            if remote_url.startswith("git@"):
                # git@github.com:owner/repo.git
                parts = remote_url.split(":")[-1].replace(".git", "").split("/")
            else:
                # https://github.com/owner/repo.git
                parts = (
                    remote_url.split("github.com/")[-1].replace(".git", "").split("/")
                )

            if len(parts) >= 2:
                return (parts[0], parts[1])
    except (subprocess.SubprocessError, IndexError):
        pass

    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    repo_env = os.getenv("GITHUB_REPOSITORY")
    if repo_env:
        parts = repo_env.split("/")
        if len(parts) == 2:
            return (parts[0], parts[1])

    return None


def get_required_checks_from_github_api(branch: str = "dev") -> Optional[List[str]]:
    """é€šè¿‡GitHub APIæŸ¥è¯¢åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸­çš„å¿…éœ€æ£€æŸ¥"""
    repo_info = get_github_repo_info()
    if not repo_info:
        return None

    owner, repo = repo_info

    # æ–¹æ³•1: ä½¿ç”¨GitHub CLI (gh)
    try:
        result = subprocess.run(
            [
                "gh",
                "api",
                f"repos/{owner}/{repo}/branches/{branch}/protection",
                "--jq",
                ".required_status_checks.contexts",
            ],
            capture_output=True,
            text=True,
            check=True,
            timeout=10,
        )

        if result.returncode == 0 and result.stdout.strip():
            contexts = json.loads(result.stdout.strip())
            if isinstance(contexts, list) and contexts:
                print(f"ğŸ“¡ ä»GitHub APIè·å–åˆ° {branch} åˆ†æ”¯çš„ {len(contexts)} ä¸ªå¿…éœ€æ£€æŸ¥")
                return contexts
    except (subprocess.SubprocessError, json.JSONDecodeError, FileNotFoundError):
        pass

    # æ–¹æ³•2: ä½¿ç”¨GitHub API (curl + token)
    github_token = os.getenv("GITHUB_TOKEN") or os.getenv("GH_TOKEN")
    if github_token:
        try:
            import urllib.error
            import urllib.request

            url = (
                f"https://api.github.com/repos/{owner}/{repo}/branches/"
                f"{branch}/protection"
            )
            headers = {
                "Accept": "application/vnd.github.v3+json",
                "Authorization": f"token {github_token}",
            }

            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode())
                contexts = data.get("required_status_checks", {}).get("contexts", [])
                if contexts:
                    print(f"ğŸ“¡ ä»GitHub APIè·å–åˆ° {branch} åˆ†æ”¯çš„ {len(contexts)} ä¸ªå¿…éœ€æ£€æŸ¥")
                    return contexts
        except (
            urllib.error.URLError,
            urllib.error.HTTPError,
            json.JSONDecodeError,
            KeyError,
        ):
            pass

    return None


def get_required_checks_from_config_file() -> Optional[List[str]]:
    """ä»é…ç½®æ–‡ä»¶è¯»å–å¿…éœ€æ£€æŸ¥"""
    config_file = Path(".github/branch-protection-checks.yaml")
    if config_file.exists():
        try:
            with open(config_file, encoding="utf-8") as f:
                config = yaml.safe_load(f)
                checks = config.get("required_checks", [])
                if checks:
                    print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶è¯»å–åˆ° {len(checks)} ä¸ªå¿…éœ€æ£€æŸ¥")
                    return checks
        except (yaml.YAMLError, KeyError):
            pass

    return None


def get_required_checks_fallback() -> List[str]:
    """å›é€€æ–¹æ¡ˆï¼šç¡¬ç¼–ç çš„å¿…éœ€æ£€æŸ¥ï¼ˆä»…åœ¨æ²¡æœ‰å…¶ä»–æ–¹æ³•æ—¶ä½¿ç”¨ï¼‰"""
    print("âš ï¸  æ— æ³•ä»GitHub APIæˆ–é…ç½®æ–‡ä»¶è·å–ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„å¿…éœ€æ£€æŸ¥")
    print("ğŸ’¡ å»ºè®®ï¼šé…ç½®GITHUB_TOKENç¯å¢ƒå˜é‡æˆ–åˆ›å»º.github/branch-protection-checks.yaml")
    return [
        "Push Validation Pipeline / run-tests (backend-unit-tests)",
        "Push Validation Pipeline / run-tests (frontend-unit-tests)",
        "Test Suite Component / unit-tests (backend)",
        "Test Suite Component / unit-tests (frontend)",
        "Test Suite Component / integration-tests",
        "Test Suite Component / e2e-tests",
        "Pre-Release Quality Check / basic-checks (lint-backend)",
        "Pre-Release Quality Check / basic-checks (lint-frontend)",
    ]


def get_required_checks(branches: List[str] = None) -> List[str]:
    """
    è·å–å¿…éœ€çš„çŠ¶æ€æ£€æŸ¥ï¼ŒæŒ‰ä¼˜å…ˆçº§ï¼š
    1. GitHub APIæŸ¥è¯¢ï¼ˆdevå’Œmainåˆ†æ”¯ï¼‰
    2. é…ç½®æ–‡ä»¶
    3. ç¡¬ç¼–ç å›é€€
    """
    if branches is None:
        branches = ["dev", "main"]

    all_checks = set()

    # ä¼˜å…ˆä»GitHub APIè·å–
    for branch in branches:
        api_checks = get_required_checks_from_github_api(branch)
        if api_checks:
            all_checks.update(api_checks)

    if all_checks:
        return sorted(list(all_checks))

    # å›é€€åˆ°é…ç½®æ–‡ä»¶
    config_checks = get_required_checks_from_config_file()
    if config_checks:
        return config_checks

    # æœ€åå›é€€åˆ°ç¡¬ç¼–ç 
    return get_required_checks_fallback()


def validate_branch_protection():
    """éªŒè¯åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸å·¥ä½œæµJobåç§°ä¸€è‡´æ€§"""
    print("ğŸ” éªŒè¯åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸å·¥ä½œæµJobåç§°ä¸€è‡´æ€§...")
    print("")

    # 1. è§£ææ‰€æœ‰å·¥ä½œæµæ–‡ä»¶
    all_workflows = parse_all_workflow_jobs()

    if not all_workflows:
        print("âš ï¸  æœªæ‰¾åˆ°å·¥ä½œæµæ–‡ä»¶")
        return True

    # 2. è·å–å¿…éœ€çš„æ£€æŸ¥ï¼ˆä»GitHub APIã€é…ç½®æ–‡ä»¶æˆ–å›é€€æ–¹æ¡ˆï¼‰
    required_checks = get_required_checks()

    # 3. æ„å»ºæ‰€æœ‰å¯ç”¨çš„jobåç§°ï¼ˆåŒ…å«å·¥ä½œæµåç§°å‰ç¼€ï¼‰
    all_available_jobs = set()
    for workflow_name, workflow_info in all_workflows.items():
        for job_name in workflow_info["jobs"]:
            # æ ¼å¼: Workflow Name / job_name
            full_job_name = f"{workflow_name} / {job_name}"
            all_available_jobs.add(full_job_name)
            # ä¹Ÿæ·»åŠ ä¸å¸¦å‰ç¼€çš„ç‰ˆæœ¬
            all_available_jobs.add(job_name)

    # 4. éªŒè¯æ¯ä¸ªå¿…éœ€çš„æ£€æŸ¥
    missing_checks = []
    found_checks = []

    for required_check in required_checks:
        # å°è¯•ç²¾ç¡®åŒ¹é…
        if required_check in all_available_jobs:
            found_checks.append(required_check)
            continue

        # å°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆæ£€æŸ¥jobåç§°æ˜¯å¦åŒ…å«åœ¨required_checkä¸­ï¼‰
        check_parts = required_check.split(" / ")
        if len(check_parts) >= 2:
            job_part = check_parts[-1]  # æœ€åä¸€éƒ¨åˆ†æ˜¯jobåç§°
            if any(job_part in job for job in all_available_jobs):
                found_checks.append(required_check)
                continue

        missing_checks.append(required_check)

    # 5. æ˜¾ç¤ºç»“æœ
    if found_checks:
        print("âœ… æ‰¾åˆ°çš„å¿…éœ€æ£€æŸ¥:")
        for check in found_checks:
            print(f"  âœ… {check}")

    if missing_checks:
        print("")
        print("âŒ ç¼ºå¤±çš„å¿…éœ€æ£€æŸ¥:")
        for check in missing_checks:
            print(f"  âŒ {check}")

        print("")
        print("ğŸ’¡ ä¿®å¤å»ºè®®:")
        print("  1. æ£€æŸ¥å·¥ä½œæµæ–‡ä»¶ä¸­çš„jobåç§°æ˜¯å¦æ­£ç¡®")
        print("  2. ç¡®ä¿å·¥ä½œæµåç§°ä¸åˆ†æ”¯ä¿æŠ¤è§„åˆ™ä¸­çš„åç§°åŒ¹é…")
        print("  3. å¦‚æœä½¿ç”¨matrixç­–ç•¥ï¼Œç¡®ä¿ç”Ÿæˆçš„jobåç§°æ ¼å¼æ­£ç¡®")
        print("")
        print("ğŸ“‹ å½“å‰å·¥ä½œæµä¸­çš„job:")
        for workflow_name, workflow_info in all_workflows.items():
            print(f"  {workflow_name}:")
            for job_name in sorted(workflow_info["jobs"]):
                print(f"    - {job_name}")

        return False

    print("")
    print("âœ… æ‰€æœ‰å¿…éœ€æ£€æŸ¥éƒ½åœ¨å·¥ä½œæµä¸­æ‰¾åˆ°")
    return True


def main():
    """ä¸»å‡½æ•°"""
    is_valid = validate_branch_protection()
    sys.exit(0 if is_valid else 1)


if __name__ == "__main__":
    main()
