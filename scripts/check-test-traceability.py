#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç”¨ä¾‹è¿½æº¯æ€§æ£€æŸ¥è„šæœ¬

æ£€æŸ¥PRDã€æµ‹è¯•ç”¨ä¾‹CSVå’Œå®é™…æµ‹è¯•ä»£ç çš„å¯¹åº”å…³ç³»ï¼š
1. PRDä¸­å£°æ˜çš„test_filesæ˜¯å¦å®é™…å­˜åœ¨
2. æµ‹è¯•ç”¨ä¾‹CSVä¸­çš„ç”¨ä¾‹æ˜¯å¦åœ¨æµ‹è¯•ä»£ç ä¸­å®ç°
3. æµ‹è¯•ä»£ç ä¸­çš„ç”¨ä¾‹IDæ˜¯å¦åœ¨CSVä¸­å£°æ˜
"""

import csv
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent


def extract_prd_metadata(prd_path: Path) -> Dict:
    """æå–PRDçš„å…ƒæ•°æ®"""
    content = prd_path.read_text(encoding="utf-8")

    # æå–YAML frontmatter
    if not content.startswith("---"):
        return {}

    parts = content.split("---", 2)
    if len(parts) < 3:
        return {}

    import yaml

    try:
        metadata = yaml.safe_load(parts[1])
        return metadata
    except Exception:
        return {}


def read_testcase_csv(csv_path: Path) -> List[Dict]:
    """è¯»å–æµ‹è¯•ç”¨ä¾‹CSVæ–‡ä»¶"""
    if not csv_path.exists():
        return []

    testcases = []
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            testcases.append(row)

    return testcases


def extract_testcase_ids_from_code(file_path: Path) -> Set[str]:
    """ä»æµ‹è¯•ä»£ç æ–‡ä»¶ä¸­æå–ç”¨ä¾‹ID"""
    if not file_path.exists():
        return set()

    content = file_path.read_text(encoding="utf-8")
    testcase_ids = set()

    # åŒ¹é… TESTCASE-IDS: TC-XXX-001, TC-XXX-002 æ ¼å¼
    pattern1 = r"TESTCASE-IDS:\s*([A-Z0-9_-]+(?:\s*,\s*[A-Z0-9_-]+)*)"
    matches1 = re.findall(pattern1, content)
    for match in matches1:
        ids = [id.strip() for id in match.split(",")]
        testcase_ids.update(ids)

    # åŒ¹é… test('TC-XXX-001: ...') æ ¼å¼
    pattern2 = r"test\(['\"]TC-([A-Z0-9_-]+):"
    matches2 = re.findall(pattern2, content)
    for match in matches2:
        testcase_ids.add(f"TC-{match}")

    # åŒ¹é… test('TC-XXX-001', ...) æ ¼å¼
    pattern3 = r"test\(['\"]TC-([A-Z0-9_-]+)['\"]"
    matches3 = re.findall(pattern3, content)
    for match in matches3:
        testcase_ids.add(f"TC-{match}")

    return testcase_ids


def check_prd_test_files(prd_path: Path, metadata: Dict) -> Tuple[List[str], List[str]]:
    """æ£€æŸ¥PRDä¸­å£°æ˜çš„test_filesæ˜¯å¦å­˜åœ¨"""
    missing_files = []
    existing_files = []

    test_files = metadata.get("test_files", [])
    for test_file in test_files:
        file_path = PROJECT_ROOT / test_file
        if file_path.exists():
            existing_files.append(test_file)
        else:
            missing_files.append(test_file)

    return existing_files, missing_files


def check_testcase_coverage(prd_path: Path, csv_path: Path, metadata: Dict) -> Dict:
    """æ£€æŸ¥æµ‹è¯•ç”¨ä¾‹è¦†ç›–æƒ…å†µ"""
    # è¯»å–CSVä¸­çš„ç”¨ä¾‹ID
    testcases = read_testcase_csv(csv_path)
    csv_case_ids = {tc["ç”¨ä¾‹ID"] for tc in testcases if "ç”¨ä¾‹ID" in tc}

    # ä»æµ‹è¯•ä»£ç ä¸­æå–ç”¨ä¾‹ID
    code_case_ids = set()
    test_files = metadata.get("test_files", [])
    for test_file in test_files:
        file_path = PROJECT_ROOT / test_file
        if file_path.exists():
            ids = extract_testcase_ids_from_code(file_path)
            code_case_ids.update(ids)

    # å¯¹æ¯”
    missing_in_code = csv_case_ids - code_case_ids
    extra_in_code = code_case_ids - csv_case_ids

    return {
        "csv_total": len(csv_case_ids),
        "code_total": len(code_case_ids),
        "matched": len(csv_case_ids & code_case_ids),
        "missing_in_code": sorted(missing_in_code),
        "extra_in_code": sorted(extra_in_code),
        "csv_case_ids": sorted(csv_case_ids),
        "code_case_ids": sorted(code_case_ids),
    }


def main():
    """ä¸»å‡½æ•°"""
    prd_dir = PROJECT_ROOT / "docs/00_product/requirements"

    if not prd_dir.exists():
        print(f"âŒ PRDç›®å½•ä¸å­˜åœ¨: {prd_dir}")
        return

    print("=" * 80)
    print("æµ‹è¯•ç”¨ä¾‹è¿½æº¯æ€§æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 80)
    print()

    all_issues = []

    # éå†æ‰€æœ‰PRDæ–‡ä»¶
    for prd_path in prd_dir.glob("**/*.md"):
        if prd_path.name.startswith("."):
            continue

        # è·³è¿‡éPRDæ–‡ä»¶
        if not prd_path.name.startswith("REQ-"):
            continue

        print(f"\nğŸ“„ æ£€æŸ¥PRD: {prd_path.relative_to(PROJECT_ROOT)}")
        print("-" * 80)

        # æå–å…ƒæ•°æ®
        metadata = extract_prd_metadata(prd_path)
        if not metadata:
            print("  âš ï¸  æ— æ³•è§£æPRDå…ƒæ•°æ®")
            continue

        req_id = metadata.get("req_id", "UNKNOWN")
        print(f"  REQ-ID: {req_id}")

        # 1. æ£€æŸ¥test_filesæ˜¯å¦å­˜åœ¨
        existing_files, missing_files = check_prd_test_files(prd_path, metadata)

        if missing_files:
            print(f"\n  âŒ ç¼ºå¤±çš„æµ‹è¯•æ–‡ä»¶ ({len(missing_files)}ä¸ª):")
            for f in missing_files:
                print(f"     - {f}")
                all_issues.append(
                    {"type": "missing_test_file", "req_id": req_id, "file": f}
                )
        else:
            print(f"\n  âœ… æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½å­˜åœ¨ ({len(existing_files)}ä¸ª)")

        # 2. æ£€æŸ¥æµ‹è¯•ç”¨ä¾‹CSV
        testcase_file = metadata.get("testcase_file", "")
        if not testcase_file:
            print("\n  âš ï¸  PRDä¸­æœªå£°æ˜testcase_file")
            all_issues.append(
                {"type": "missing_testcase_file_metadata", "req_id": req_id}
            )
            continue

        csv_path = PROJECT_ROOT / testcase_file
        if not csv_path.exists():
            print(f"\n  âŒ æµ‹è¯•ç”¨ä¾‹CSVæ–‡ä»¶ä¸å­˜åœ¨: {testcase_file}")
            all_issues.append(
                {
                    "type": "missing_testcase_csv",
                    "req_id": req_id,
                    "file": testcase_file,
                }
            )
            continue

        print(f"\n  âœ… æµ‹è¯•ç”¨ä¾‹CSVå­˜åœ¨: {csv_path.relative_to(PROJECT_ROOT)}")

        # 3. æ£€æŸ¥æµ‹è¯•ç”¨ä¾‹è¦†ç›–
        coverage = check_testcase_coverage(prd_path, csv_path, metadata)

        print("\n  ğŸ“Š æµ‹è¯•ç”¨ä¾‹è¦†ç›–æƒ…å†µ:")
        print(f"     CSVä¸­ç”¨ä¾‹æ€»æ•°: {coverage['csv_total']}")
        print(f"     ä»£ç ä¸­ç”¨ä¾‹æ€»æ•°: {coverage['code_total']}")
        print(f"     å·²åŒ¹é…ç”¨ä¾‹æ•°: {coverage['matched']}")

        if coverage["missing_in_code"]:
            print(f"\n  âŒ CSVä¸­æœ‰ä½†ä»£ç ä¸­ç¼ºå¤±çš„ç”¨ä¾‹ ({len(coverage['missing_in_code'])}ä¸ª):")
            for case_id in coverage["missing_in_code"][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"     - {case_id}")
            if len(coverage["missing_in_code"]) > 10:
                print(f"     ... è¿˜æœ‰ {len(coverage['missing_in_code']) - 10} ä¸ª")
            all_issues.append(
                {
                    "type": "missing_testcase_in_code",
                    "req_id": req_id,
                    "cases": coverage["missing_in_code"],
                }
            )

        if coverage["extra_in_code"]:
            print(f"\n  âš ï¸  ä»£ç ä¸­æœ‰ä½†CSVä¸­æœªå£°æ˜çš„ç”¨ä¾‹ ({len(coverage['extra_in_code'])}ä¸ª):")
            for case_id in coverage["extra_in_code"][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"     - {case_id}")
            if len(coverage["extra_in_code"]) > 5:
                print(f"     ... è¿˜æœ‰ {len(coverage['extra_in_code']) - 5} ä¸ª")

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æ£€æŸ¥æ€»ç»“")
    print("=" * 80)

    if not all_issues:
        print("\nâœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼PRDã€æµ‹è¯•ç”¨ä¾‹CSVå’Œæµ‹è¯•ä»£ç å®Œå…¨å¯¹åº”ã€‚")
        return 0
    else:
        print(f"\nâŒ å‘ç° {len(all_issues)} ç±»é—®é¢˜éœ€è¦ä¿®å¤ï¼š")

        issue_types = {}
        for issue in all_issues:
            issue_type = issue["type"]
            if issue_type not in issue_types:
                issue_types[issue_type] = []
            issue_types[issue_type].append(issue)

        for issue_type, issues in issue_types.items():
            print(f"\n  {issue_type}: {len(issues)} ä¸ª")

        return 1


if __name__ == "__main__":
    import sys

    sys.exit(main())
